{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29eedd06-4cd6-41fc-aa4e-569dd4f521bd",
   "metadata": {},
   "source": [
    "# Предсказание атрибутов узлов с использованием графовых нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b687e9-05ef-4908-8bde-2b5dbbe576b6",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Курс \"Машинное обучение на графах\", Лекции 4-5 \"Графовые нейронные сети\"\n",
    "* Документация:\n",
    "    * https://docs.dgl.ai/en/latest/tutorials/blitz/2_dglgraph.html\n",
    "    * https://docs.dgl.ai/en/latest/tutorials/blitz/1_introduction.html\n",
    "    * https://docs.dgl.ai/generated/dgl.nn.pytorch.conv.GraphConv.html#dgl.nn.pytorch.conv.GraphConv\n",
    "    * https://docs.dgl.ai/api/python/dgl.data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ab35d-a7c0-4237-a394-691389c7c773",
   "metadata": {},
   "source": [
    "## Вопросы для совместного обсуждения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea53db8-da33-43ee-95e0-9876384499c1",
   "metadata": {},
   "source": [
    "1\\. Обсудите основные шаги для решения задачи предсказания атрибутов узлов при помощи графовых нейронных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7895c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49092535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорты (для всех последующих примеров):\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.data\n",
    "import dgl.nn as gnn\n",
    "\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e576598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch; print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7926693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4e1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import train_cora_node_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f786de8-ba69-4d86-b997-e55c9028acad",
   "metadata": {},
   "source": [
    "## Задачи для самостоятельного решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a6cb0-9b05-4a80-a4cc-a2f70d9cbfd7",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"1\"></p>\n",
    "\n",
    "1\\. Загрузите граф `CoraGraphDataset` из `dgl.data`. Решите задачу классификации узлов графа, используя только полносвязные слои `torch.nn.Linear` (создайте модель из двух слоев). Обратите внимание, что настройка весов модели должна проводиться только на основе примеров из обучающей выборки. Посчитайте и выведите на экран значение `accuracy` на тестовой выборке.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95791206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "G = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "936694d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear( n_inputs, 10\n",
    "                                )\n",
    "        self.linear2 = nn.Linear(10, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "            return torch.relu(self.linear2(self.linear1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9604f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = G.ndata['train_mask']\n",
    "val_mask = G.ndata['val_mask']\n",
    "train_mask = G.ndata['test_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09443f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = G.ndata['feat'].shape[1]\n",
    "n_out = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab1de529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1433, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input, n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "283e3f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9617, grad_fn=<NllLossBackward0>)\n",
      "1 tensor(1.9560, grad_fn=<NllLossBackward0>)\n",
      "2 tensor(1.9502, grad_fn=<NllLossBackward0>)\n",
      "3 tensor(1.9440, grad_fn=<NllLossBackward0>)\n",
      "4 tensor(1.9385, grad_fn=<NllLossBackward0>)\n",
      "5 tensor(1.9347, grad_fn=<NllLossBackward0>)\n",
      "6 tensor(1.9304, grad_fn=<NllLossBackward0>)\n",
      "7 tensor(1.9269, grad_fn=<NllLossBackward0>)\n",
      "8 tensor(1.9241, grad_fn=<NllLossBackward0>)\n",
      "9 tensor(1.9200, grad_fn=<NllLossBackward0>)\n",
      "10 tensor(1.9157, grad_fn=<NllLossBackward0>)\n",
      "11 tensor(1.9115, grad_fn=<NllLossBackward0>)\n",
      "12 tensor(1.9068, grad_fn=<NllLossBackward0>)\n",
      "13 tensor(1.9020, grad_fn=<NllLossBackward0>)\n",
      "14 tensor(1.8970, grad_fn=<NllLossBackward0>)\n",
      "15 tensor(1.8920, grad_fn=<NllLossBackward0>)\n",
      "16 tensor(1.8868, grad_fn=<NllLossBackward0>)\n",
      "17 tensor(1.8816, grad_fn=<NllLossBackward0>)\n",
      "18 tensor(1.8762, grad_fn=<NllLossBackward0>)\n",
      "19 tensor(1.8705, grad_fn=<NllLossBackward0>)\n",
      "20 tensor(1.8644, grad_fn=<NllLossBackward0>)\n",
      "21 tensor(1.8581, grad_fn=<NllLossBackward0>)\n",
      "22 tensor(1.8515, grad_fn=<NllLossBackward0>)\n",
      "23 tensor(1.8448, grad_fn=<NllLossBackward0>)\n",
      "24 tensor(1.8381, grad_fn=<NllLossBackward0>)\n",
      "25 tensor(1.8312, grad_fn=<NllLossBackward0>)\n",
      "26 tensor(1.8242, grad_fn=<NllLossBackward0>)\n",
      "27 tensor(1.8170, grad_fn=<NllLossBackward0>)\n",
      "28 tensor(1.8095, grad_fn=<NllLossBackward0>)\n",
      "29 tensor(1.8018, grad_fn=<NllLossBackward0>)\n",
      "30 tensor(1.7940, grad_fn=<NllLossBackward0>)\n",
      "31 tensor(1.7861, grad_fn=<NllLossBackward0>)\n",
      "32 tensor(1.7782, grad_fn=<NllLossBackward0>)\n",
      "33 tensor(1.7702, grad_fn=<NllLossBackward0>)\n",
      "34 tensor(1.7621, grad_fn=<NllLossBackward0>)\n",
      "35 tensor(1.7539, grad_fn=<NllLossBackward0>)\n",
      "36 tensor(1.7455, grad_fn=<NllLossBackward0>)\n",
      "37 tensor(1.7371, grad_fn=<NllLossBackward0>)\n",
      "38 tensor(1.7286, grad_fn=<NllLossBackward0>)\n",
      "39 tensor(1.7201, grad_fn=<NllLossBackward0>)\n",
      "40 tensor(1.7115, grad_fn=<NllLossBackward0>)\n",
      "41 tensor(1.7028, grad_fn=<NllLossBackward0>)\n",
      "42 tensor(1.6942, grad_fn=<NllLossBackward0>)\n",
      "43 tensor(1.6855, grad_fn=<NllLossBackward0>)\n",
      "44 tensor(1.6767, grad_fn=<NllLossBackward0>)\n",
      "45 tensor(1.6680, grad_fn=<NllLossBackward0>)\n",
      "46 tensor(1.6592, grad_fn=<NllLossBackward0>)\n",
      "47 tensor(1.6504, grad_fn=<NllLossBackward0>)\n",
      "48 tensor(1.6416, grad_fn=<NllLossBackward0>)\n",
      "49 tensor(1.6329, grad_fn=<NllLossBackward0>)\n",
      "50 tensor(1.6241, grad_fn=<NllLossBackward0>)\n",
      "51 tensor(1.6154, grad_fn=<NllLossBackward0>)\n",
      "52 tensor(1.6068, grad_fn=<NllLossBackward0>)\n",
      "53 tensor(1.5982, grad_fn=<NllLossBackward0>)\n",
      "54 tensor(1.5897, grad_fn=<NllLossBackward0>)\n",
      "55 tensor(1.5812, grad_fn=<NllLossBackward0>)\n",
      "56 tensor(1.5729, grad_fn=<NllLossBackward0>)\n",
      "57 tensor(1.5647, grad_fn=<NllLossBackward0>)\n",
      "58 tensor(1.5565, grad_fn=<NllLossBackward0>)\n",
      "59 tensor(1.5485, grad_fn=<NllLossBackward0>)\n",
      "60 tensor(1.5407, grad_fn=<NllLossBackward0>)\n",
      "61 tensor(1.5330, grad_fn=<NllLossBackward0>)\n",
      "62 tensor(1.5254, grad_fn=<NllLossBackward0>)\n",
      "63 tensor(1.5180, grad_fn=<NllLossBackward0>)\n",
      "64 tensor(1.5107, grad_fn=<NllLossBackward0>)\n",
      "65 tensor(1.5036, grad_fn=<NllLossBackward0>)\n",
      "66 tensor(1.4967, grad_fn=<NllLossBackward0>)\n",
      "67 tensor(1.4899, grad_fn=<NllLossBackward0>)\n",
      "68 tensor(1.4833, grad_fn=<NllLossBackward0>)\n",
      "69 tensor(1.4767, grad_fn=<NllLossBackward0>)\n",
      "70 tensor(1.4703, grad_fn=<NllLossBackward0>)\n",
      "71 tensor(1.4639, grad_fn=<NllLossBackward0>)\n",
      "72 tensor(1.4576, grad_fn=<NllLossBackward0>)\n",
      "73 tensor(1.4510, grad_fn=<NllLossBackward0>)\n",
      "74 tensor(1.4445, grad_fn=<NllLossBackward0>)\n",
      "75 tensor(1.4377, grad_fn=<NllLossBackward0>)\n",
      "76 tensor(1.4308, grad_fn=<NllLossBackward0>)\n",
      "77 tensor(1.4234, grad_fn=<NllLossBackward0>)\n",
      "78 tensor(1.4158, grad_fn=<NllLossBackward0>)\n",
      "79 tensor(1.4080, grad_fn=<NllLossBackward0>)\n",
      "80 tensor(1.4002, grad_fn=<NllLossBackward0>)\n",
      "81 tensor(1.3922, grad_fn=<NllLossBackward0>)\n",
      "82 tensor(1.3843, grad_fn=<NllLossBackward0>)\n",
      "83 tensor(1.3766, grad_fn=<NllLossBackward0>)\n",
      "84 tensor(1.3690, grad_fn=<NllLossBackward0>)\n",
      "85 tensor(1.3616, grad_fn=<NllLossBackward0>)\n",
      "86 tensor(1.3545, grad_fn=<NllLossBackward0>)\n",
      "87 tensor(1.3474, grad_fn=<NllLossBackward0>)\n",
      "88 tensor(1.3405, grad_fn=<NllLossBackward0>)\n",
      "89 tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
      "90 tensor(1.3265, grad_fn=<NllLossBackward0>)\n",
      "91 tensor(1.3193, grad_fn=<NllLossBackward0>)\n",
      "92 tensor(1.3119, grad_fn=<NllLossBackward0>)\n",
      "93 tensor(1.3042, grad_fn=<NllLossBackward0>)\n",
      "94 tensor(1.2962, grad_fn=<NllLossBackward0>)\n",
      "95 tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
      "96 tensor(1.2793, grad_fn=<NllLossBackward0>)\n",
      "97 tensor(1.2705, grad_fn=<NllLossBackward0>)\n",
      "98 tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
      "99 tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "100 tensor(1.2440, grad_fn=<NllLossBackward0>)\n",
      "101 tensor(1.2355, grad_fn=<NllLossBackward0>)\n",
      "102 tensor(1.2272, grad_fn=<NllLossBackward0>)\n",
      "103 tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
      "104 tensor(1.2114, grad_fn=<NllLossBackward0>)\n",
      "105 tensor(1.2038, grad_fn=<NllLossBackward0>)\n",
      "106 tensor(1.1964, grad_fn=<NllLossBackward0>)\n",
      "107 tensor(1.1891, grad_fn=<NllLossBackward0>)\n",
      "108 tensor(1.1820, grad_fn=<NllLossBackward0>)\n",
      "109 tensor(1.1750, grad_fn=<NllLossBackward0>)\n",
      "110 tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "111 tensor(1.1617, grad_fn=<NllLossBackward0>)\n",
      "112 tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
      "113 tensor(1.1494, grad_fn=<NllLossBackward0>)\n",
      "114 tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
      "115 tensor(1.1381, grad_fn=<NllLossBackward0>)\n",
      "116 tensor(1.1329, grad_fn=<NllLossBackward0>)\n",
      "117 tensor(1.1279, grad_fn=<NllLossBackward0>)\n",
      "118 tensor(1.1231, grad_fn=<NllLossBackward0>)\n",
      "119 tensor(1.1185, grad_fn=<NllLossBackward0>)\n",
      "120 tensor(1.1141, grad_fn=<NllLossBackward0>)\n",
      "121 tensor(1.1098, grad_fn=<NllLossBackward0>)\n",
      "122 tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "123 tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "124 tensor(1.0980, grad_fn=<NllLossBackward0>)\n",
      "125 tensor(1.0944, grad_fn=<NllLossBackward0>)\n",
      "126 tensor(1.0910, grad_fn=<NllLossBackward0>)\n",
      "127 tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "128 tensor(1.0845, grad_fn=<NllLossBackward0>)\n",
      "129 tensor(1.0814, grad_fn=<NllLossBackward0>)\n",
      "130 tensor(1.0785, grad_fn=<NllLossBackward0>)\n",
      "131 tensor(1.0757, grad_fn=<NllLossBackward0>)\n",
      "132 tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
      "133 tensor(1.0704, grad_fn=<NllLossBackward0>)\n",
      "134 tensor(1.0679, grad_fn=<NllLossBackward0>)\n",
      "135 tensor(1.0656, grad_fn=<NllLossBackward0>)\n",
      "136 tensor(1.0633, grad_fn=<NllLossBackward0>)\n",
      "137 tensor(1.0611, grad_fn=<NllLossBackward0>)\n",
      "138 tensor(1.0590, grad_fn=<NllLossBackward0>)\n",
      "139 tensor(1.0570, grad_fn=<NllLossBackward0>)\n",
      "140 tensor(1.0551, grad_fn=<NllLossBackward0>)\n",
      "141 tensor(1.0533, grad_fn=<NllLossBackward0>)\n",
      "142 tensor(1.0515, grad_fn=<NllLossBackward0>)\n",
      "143 tensor(1.0498, grad_fn=<NllLossBackward0>)\n",
      "144 tensor(1.0482, grad_fn=<NllLossBackward0>)\n",
      "145 tensor(1.0467, grad_fn=<NllLossBackward0>)\n",
      "146 tensor(1.0452, grad_fn=<NllLossBackward0>)\n",
      "147 tensor(1.0438, grad_fn=<NllLossBackward0>)\n",
      "148 tensor(1.0425, grad_fn=<NllLossBackward0>)\n",
      "149 tensor(1.0412, grad_fn=<NllLossBackward0>)\n",
      "150 tensor(1.0399, grad_fn=<NllLossBackward0>)\n",
      "151 tensor(1.0387, grad_fn=<NllLossBackward0>)\n",
      "152 tensor(1.0376, grad_fn=<NllLossBackward0>)\n",
      "153 tensor(1.0365, grad_fn=<NllLossBackward0>)\n",
      "154 tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
      "155 tensor(1.0344, grad_fn=<NllLossBackward0>)\n",
      "156 tensor(1.0334, grad_fn=<NllLossBackward0>)\n",
      "157 tensor(1.0325, grad_fn=<NllLossBackward0>)\n",
      "158 tensor(1.0316, grad_fn=<NllLossBackward0>)\n",
      "159 tensor(1.0308, grad_fn=<NllLossBackward0>)\n",
      "160 tensor(1.0300, grad_fn=<NllLossBackward0>)\n",
      "161 tensor(1.0292, grad_fn=<NllLossBackward0>)\n",
      "162 tensor(1.0284, grad_fn=<NllLossBackward0>)\n",
      "163 tensor(1.0277, grad_fn=<NllLossBackward0>)\n",
      "164 tensor(1.0271, grad_fn=<NllLossBackward0>)\n",
      "165 tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
      "166 tensor(1.0258, grad_fn=<NllLossBackward0>)\n",
      "167 tensor(1.0252, grad_fn=<NllLossBackward0>)\n",
      "168 tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
      "169 tensor(1.0240, grad_fn=<NllLossBackward0>)\n",
      "170 tensor(1.0235, grad_fn=<NllLossBackward0>)\n",
      "171 tensor(1.0230, grad_fn=<NllLossBackward0>)\n",
      "172 tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "173 tensor(1.0220, grad_fn=<NllLossBackward0>)\n",
      "174 tensor(1.0215, grad_fn=<NllLossBackward0>)\n",
      "175 tensor(1.0211, grad_fn=<NllLossBackward0>)\n",
      "176 tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
      "177 tensor(1.0202, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 tensor(1.0199, grad_fn=<NllLossBackward0>)\n",
      "179 tensor(1.0195, grad_fn=<NllLossBackward0>)\n",
      "180 tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "181 tensor(1.0187, grad_fn=<NllLossBackward0>)\n",
      "182 tensor(1.0184, grad_fn=<NllLossBackward0>)\n",
      "183 tensor(1.0182, grad_fn=<NllLossBackward0>)\n",
      "184 tensor(1.0178, grad_fn=<NllLossBackward0>)\n",
      "185 tensor(1.0175, grad_fn=<NllLossBackward0>)\n",
      "186 tensor(1.0172, grad_fn=<NllLossBackward0>)\n",
      "187 tensor(1.0169, grad_fn=<NllLossBackward0>)\n",
      "188 tensor(1.0166, grad_fn=<NllLossBackward0>)\n",
      "189 tensor(1.0164, grad_fn=<NllLossBackward0>)\n",
      "190 tensor(1.0161, grad_fn=<NllLossBackward0>)\n",
      "191 tensor(1.0159, grad_fn=<NllLossBackward0>)\n",
      "192 tensor(1.0156, grad_fn=<NllLossBackward0>)\n",
      "193 tensor(1.0154, grad_fn=<NllLossBackward0>)\n",
      "194 tensor(1.0151, grad_fn=<NllLossBackward0>)\n",
      "195 tensor(1.0149, grad_fn=<NllLossBackward0>)\n",
      "196 tensor(1.0147, grad_fn=<NllLossBackward0>)\n",
      "197 tensor(1.0145, grad_fn=<NllLossBackward0>)\n",
      "198 tensor(1.0143, grad_fn=<NllLossBackward0>)\n",
      "199 tensor(1.0141, grad_fn=<NllLossBackward0>)\n",
      "200 tensor(1.0140, grad_fn=<NllLossBackward0>)\n",
      "201 tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
      "202 tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
      "203 tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "204 tensor(1.0133, grad_fn=<NllLossBackward0>)\n",
      "205 tensor(1.0132, grad_fn=<NllLossBackward0>)\n",
      "206 tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "207 tensor(1.0129, grad_fn=<NllLossBackward0>)\n",
      "208 tensor(1.0127, grad_fn=<NllLossBackward0>)\n",
      "209 tensor(1.0125, grad_fn=<NllLossBackward0>)\n",
      "210 tensor(1.0124, grad_fn=<NllLossBackward0>)\n",
      "211 tensor(1.0122, grad_fn=<NllLossBackward0>)\n",
      "212 tensor(1.0121, grad_fn=<NllLossBackward0>)\n",
      "213 tensor(1.0119, grad_fn=<NllLossBackward0>)\n",
      "214 tensor(1.0117, grad_fn=<NllLossBackward0>)\n",
      "215 tensor(1.0116, grad_fn=<NllLossBackward0>)\n",
      "216 tensor(1.0115, grad_fn=<NllLossBackward0>)\n",
      "217 tensor(1.0114, grad_fn=<NllLossBackward0>)\n",
      "218 tensor(1.0112, grad_fn=<NllLossBackward0>)\n",
      "219 tensor(1.0111, grad_fn=<NllLossBackward0>)\n",
      "220 tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "221 tensor(1.0109, grad_fn=<NllLossBackward0>)\n",
      "222 tensor(1.0108, grad_fn=<NllLossBackward0>)\n",
      "223 tensor(1.0107, grad_fn=<NllLossBackward0>)\n",
      "224 tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "225 tensor(1.0105, grad_fn=<NllLossBackward0>)\n",
      "226 tensor(1.0104, grad_fn=<NllLossBackward0>)\n",
      "227 tensor(1.0103, grad_fn=<NllLossBackward0>)\n",
      "228 tensor(1.0102, grad_fn=<NllLossBackward0>)\n",
      "229 tensor(1.0101, grad_fn=<NllLossBackward0>)\n",
      "230 tensor(1.0100, grad_fn=<NllLossBackward0>)\n",
      "231 tensor(1.0099, grad_fn=<NllLossBackward0>)\n",
      "232 tensor(1.0098, grad_fn=<NllLossBackward0>)\n",
      "233 tensor(1.0097, grad_fn=<NllLossBackward0>)\n",
      "234 tensor(1.0096, grad_fn=<NllLossBackward0>)\n",
      "235 tensor(1.0096, grad_fn=<NllLossBackward0>)\n",
      "236 tensor(1.0095, grad_fn=<NllLossBackward0>)\n",
      "237 tensor(1.0094, grad_fn=<NllLossBackward0>)\n",
      "238 tensor(1.0094, grad_fn=<NllLossBackward0>)\n",
      "239 tensor(1.0093, grad_fn=<NllLossBackward0>)\n",
      "240 tensor(1.0092, grad_fn=<NllLossBackward0>)\n",
      "241 tensor(1.0091, grad_fn=<NllLossBackward0>)\n",
      "242 tensor(1.0090, grad_fn=<NllLossBackward0>)\n",
      "243 tensor(1.0090, grad_fn=<NllLossBackward0>)\n",
      "244 tensor(1.0089, grad_fn=<NllLossBackward0>)\n",
      "245 tensor(1.0088, grad_fn=<NllLossBackward0>)\n",
      "246 tensor(1.0087, grad_fn=<NllLossBackward0>)\n",
      "247 tensor(1.0087, grad_fn=<NllLossBackward0>)\n",
      "248 tensor(1.0086, grad_fn=<NllLossBackward0>)\n",
      "249 tensor(1.0086, grad_fn=<NllLossBackward0>)\n",
      "250 tensor(1.0085, grad_fn=<NllLossBackward0>)\n",
      "251 tensor(1.0084, grad_fn=<NllLossBackward0>)\n",
      "252 tensor(1.0084, grad_fn=<NllLossBackward0>)\n",
      "253 tensor(1.0083, grad_fn=<NllLossBackward0>)\n",
      "254 tensor(1.0083, grad_fn=<NllLossBackward0>)\n",
      "255 tensor(1.0082, grad_fn=<NllLossBackward0>)\n",
      "256 tensor(1.0081, grad_fn=<NllLossBackward0>)\n",
      "257 tensor(1.0081, grad_fn=<NllLossBackward0>)\n",
      "258 tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
      "259 tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
      "260 tensor(1.0079, grad_fn=<NllLossBackward0>)\n",
      "261 tensor(1.0079, grad_fn=<NllLossBackward0>)\n",
      "262 tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
      "263 tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "264 tensor(1.0066, grad_fn=<NllLossBackward0>)\n",
      "265 tensor(1.0036, grad_fn=<NllLossBackward0>)\n",
      "266 tensor(0.9948, grad_fn=<NllLossBackward0>)\n",
      "267 tensor(0.9780, grad_fn=<NllLossBackward0>)\n",
      "268 tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "269 tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "270 tensor(0.8768, grad_fn=<NllLossBackward0>)\n",
      "271 tensor(0.8342, grad_fn=<NllLossBackward0>)\n",
      "272 tensor(0.7912, grad_fn=<NllLossBackward0>)\n",
      "273 tensor(0.7506, grad_fn=<NllLossBackward0>)\n",
      "274 tensor(0.7161, grad_fn=<NllLossBackward0>)\n",
      "275 tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
      "276 tensor(0.6772, grad_fn=<NllLossBackward0>)\n",
      "277 tensor(0.6746, grad_fn=<NllLossBackward0>)\n",
      "278 tensor(0.6791, grad_fn=<NllLossBackward0>)\n",
      "279 tensor(0.6846, grad_fn=<NllLossBackward0>)\n",
      "280 tensor(0.6860, grad_fn=<NllLossBackward0>)\n",
      "281 tensor(0.6808, grad_fn=<NllLossBackward0>)\n",
      "282 tensor(0.6697, grad_fn=<NllLossBackward0>)\n",
      "283 tensor(0.6547, grad_fn=<NllLossBackward0>)\n",
      "284 tensor(0.6382, grad_fn=<NllLossBackward0>)\n",
      "285 tensor(0.6225, grad_fn=<NllLossBackward0>)\n",
      "286 tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
      "287 tensor(0.5986, grad_fn=<NllLossBackward0>)\n",
      "288 tensor(0.5915, grad_fn=<NllLossBackward0>)\n",
      "289 tensor(0.5871, grad_fn=<NllLossBackward0>)\n",
      "290 tensor(0.5843, grad_fn=<NllLossBackward0>)\n",
      "291 tensor(0.5821, grad_fn=<NllLossBackward0>)\n",
      "292 tensor(0.5793, grad_fn=<NllLossBackward0>)\n",
      "293 tensor(0.5750, grad_fn=<NllLossBackward0>)\n",
      "294 tensor(0.5691, grad_fn=<NllLossBackward0>)\n",
      "295 tensor(0.5618, grad_fn=<NllLossBackward0>)\n",
      "296 tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
      "297 tensor(0.5457, grad_fn=<NllLossBackward0>)\n",
      "298 tensor(0.5381, grad_fn=<NllLossBackward0>)\n",
      "299 tensor(0.5314, grad_fn=<NllLossBackward0>)\n",
      "300 tensor(0.5257, grad_fn=<NllLossBackward0>)\n",
      "301 tensor(0.5209, grad_fn=<NllLossBackward0>)\n",
      "302 tensor(0.5166, grad_fn=<NllLossBackward0>)\n",
      "303 tensor(0.5126, grad_fn=<NllLossBackward0>)\n",
      "304 tensor(0.5084, grad_fn=<NllLossBackward0>)\n",
      "305 tensor(0.5041, grad_fn=<NllLossBackward0>)\n",
      "306 tensor(0.4995, grad_fn=<NllLossBackward0>)\n",
      "307 tensor(0.4946, grad_fn=<NllLossBackward0>)\n",
      "308 tensor(0.4896, grad_fn=<NllLossBackward0>)\n",
      "309 tensor(0.4846, grad_fn=<NllLossBackward0>)\n",
      "310 tensor(0.4800, grad_fn=<NllLossBackward0>)\n",
      "311 tensor(0.4759, grad_fn=<NllLossBackward0>)\n",
      "312 tensor(0.4722, grad_fn=<NllLossBackward0>)\n",
      "313 tensor(0.4689, grad_fn=<NllLossBackward0>)\n",
      "314 tensor(0.4658, grad_fn=<NllLossBackward0>)\n",
      "315 tensor(0.4629, grad_fn=<NllLossBackward0>)\n",
      "316 tensor(0.4601, grad_fn=<NllLossBackward0>)\n",
      "317 tensor(0.4574, grad_fn=<NllLossBackward0>)\n",
      "318 tensor(0.4546, grad_fn=<NllLossBackward0>)\n",
      "319 tensor(0.4519, grad_fn=<NllLossBackward0>)\n",
      "320 tensor(0.4493, grad_fn=<NllLossBackward0>)\n",
      "321 tensor(0.4469, grad_fn=<NllLossBackward0>)\n",
      "322 tensor(0.4447, grad_fn=<NllLossBackward0>)\n",
      "323 tensor(0.4426, grad_fn=<NllLossBackward0>)\n",
      "324 tensor(0.4407, grad_fn=<NllLossBackward0>)\n",
      "325 tensor(0.4389, grad_fn=<NllLossBackward0>)\n",
      "326 tensor(0.4372, grad_fn=<NllLossBackward0>)\n",
      "327 tensor(0.4355, grad_fn=<NllLossBackward0>)\n",
      "328 tensor(0.4339, grad_fn=<NllLossBackward0>)\n",
      "329 tensor(0.4324, grad_fn=<NllLossBackward0>)\n",
      "330 tensor(0.4309, grad_fn=<NllLossBackward0>)\n",
      "331 tensor(0.4295, grad_fn=<NllLossBackward0>)\n",
      "332 tensor(0.4280, grad_fn=<NllLossBackward0>)\n",
      "333 tensor(0.4267, grad_fn=<NllLossBackward0>)\n",
      "334 tensor(0.4253, grad_fn=<NllLossBackward0>)\n",
      "335 tensor(0.4241, grad_fn=<NllLossBackward0>)\n",
      "336 tensor(0.4228, grad_fn=<NllLossBackward0>)\n",
      "337 tensor(0.4217, grad_fn=<NllLossBackward0>)\n",
      "338 tensor(0.4206, grad_fn=<NllLossBackward0>)\n",
      "339 tensor(0.4195, grad_fn=<NllLossBackward0>)\n",
      "340 tensor(0.4184, grad_fn=<NllLossBackward0>)\n",
      "341 tensor(0.4174, grad_fn=<NllLossBackward0>)\n",
      "342 tensor(0.4164, grad_fn=<NllLossBackward0>)\n",
      "343 tensor(0.4155, grad_fn=<NllLossBackward0>)\n",
      "344 tensor(0.4146, grad_fn=<NllLossBackward0>)\n",
      "345 tensor(0.4137, grad_fn=<NllLossBackward0>)\n",
      "346 tensor(0.4129, grad_fn=<NllLossBackward0>)\n",
      "347 tensor(0.4121, grad_fn=<NllLossBackward0>)\n",
      "348 tensor(0.4113, grad_fn=<NllLossBackward0>)\n",
      "349 tensor(0.4106, grad_fn=<NllLossBackward0>)\n",
      "350 tensor(0.4098, grad_fn=<NllLossBackward0>)\n",
      "351 tensor(0.4091, grad_fn=<NllLossBackward0>)\n",
      "352 tensor(0.4085, grad_fn=<NllLossBackward0>)\n",
      "353 tensor(0.4078, grad_fn=<NllLossBackward0>)\n",
      "354 tensor(0.4072, grad_fn=<NllLossBackward0>)\n",
      "355 tensor(0.4065, grad_fn=<NllLossBackward0>)\n",
      "356 tensor(0.4059, grad_fn=<NllLossBackward0>)\n",
      "357 tensor(0.4054, grad_fn=<NllLossBackward0>)\n",
      "358 tensor(0.4048, grad_fn=<NllLossBackward0>)\n",
      "359 tensor(0.4043, grad_fn=<NllLossBackward0>)\n",
      "360 tensor(0.4037, grad_fn=<NllLossBackward0>)\n",
      "361 tensor(0.4032, grad_fn=<NllLossBackward0>)\n",
      "362 tensor(0.4027, grad_fn=<NllLossBackward0>)\n",
      "363 tensor(0.4022, grad_fn=<NllLossBackward0>)\n",
      "364 tensor(0.4018, grad_fn=<NllLossBackward0>)\n",
      "365 tensor(0.4013, grad_fn=<NllLossBackward0>)\n",
      "366 tensor(0.4009, grad_fn=<NllLossBackward0>)\n",
      "367 tensor(0.4005, grad_fn=<NllLossBackward0>)\n",
      "368 tensor(0.4000, grad_fn=<NllLossBackward0>)\n",
      "369 tensor(0.3996, grad_fn=<NllLossBackward0>)\n",
      "370 tensor(0.3993, grad_fn=<NllLossBackward0>)\n",
      "371 tensor(0.3989, grad_fn=<NllLossBackward0>)\n",
      "372 tensor(0.3985, grad_fn=<NllLossBackward0>)\n",
      "373 tensor(0.3982, grad_fn=<NllLossBackward0>)\n",
      "374 tensor(0.3978, grad_fn=<NllLossBackward0>)\n",
      "375 tensor(0.3975, grad_fn=<NllLossBackward0>)\n",
      "376 tensor(0.3972, grad_fn=<NllLossBackward0>)\n",
      "377 tensor(0.3969, grad_fn=<NllLossBackward0>)\n",
      "378 tensor(0.3966, grad_fn=<NllLossBackward0>)\n",
      "379 tensor(0.3963, grad_fn=<NllLossBackward0>)\n",
      "380 tensor(0.3960, grad_fn=<NllLossBackward0>)\n",
      "381 tensor(0.3957, grad_fn=<NllLossBackward0>)\n",
      "382 tensor(0.3954, grad_fn=<NllLossBackward0>)\n",
      "383 tensor(0.3952, grad_fn=<NllLossBackward0>)\n",
      "384 tensor(0.3949, grad_fn=<NllLossBackward0>)\n",
      "385 tensor(0.3947, grad_fn=<NllLossBackward0>)\n",
      "386 tensor(0.3945, grad_fn=<NllLossBackward0>)\n",
      "387 tensor(0.3942, grad_fn=<NllLossBackward0>)\n",
      "388 tensor(0.3940, grad_fn=<NllLossBackward0>)\n",
      "389 tensor(0.3938, grad_fn=<NllLossBackward0>)\n",
      "390 tensor(0.3936, grad_fn=<NllLossBackward0>)\n",
      "391 tensor(0.3934, grad_fn=<NllLossBackward0>)\n",
      "392 tensor(0.3932, grad_fn=<NllLossBackward0>)\n",
      "393 tensor(0.3930, grad_fn=<NllLossBackward0>)\n",
      "394 tensor(0.3928, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 tensor(0.3926, grad_fn=<NllLossBackward0>)\n",
      "396 tensor(0.3924, grad_fn=<NllLossBackward0>)\n",
      "397 tensor(0.3922, grad_fn=<NllLossBackward0>)\n",
      "398 tensor(0.3920, grad_fn=<NllLossBackward0>)\n",
      "399 tensor(0.3919, grad_fn=<NllLossBackward0>)\n",
      "400 tensor(0.3917, grad_fn=<NllLossBackward0>)\n",
      "401 tensor(0.3915, grad_fn=<NllLossBackward0>)\n",
      "402 tensor(0.3914, grad_fn=<NllLossBackward0>)\n",
      "403 tensor(0.3912, grad_fn=<NllLossBackward0>)\n",
      "404 tensor(0.3911, grad_fn=<NllLossBackward0>)\n",
      "405 tensor(0.3910, grad_fn=<NllLossBackward0>)\n",
      "406 tensor(0.3908, grad_fn=<NllLossBackward0>)\n",
      "407 tensor(0.3907, grad_fn=<NllLossBackward0>)\n",
      "408 tensor(0.3905, grad_fn=<NllLossBackward0>)\n",
      "409 tensor(0.3904, grad_fn=<NllLossBackward0>)\n",
      "410 tensor(0.3903, grad_fn=<NllLossBackward0>)\n",
      "411 tensor(0.3902, grad_fn=<NllLossBackward0>)\n",
      "412 tensor(0.3901, grad_fn=<NllLossBackward0>)\n",
      "413 tensor(0.3899, grad_fn=<NllLossBackward0>)\n",
      "414 tensor(0.3898, grad_fn=<NllLossBackward0>)\n",
      "415 tensor(0.3897, grad_fn=<NllLossBackward0>)\n",
      "416 tensor(0.3896, grad_fn=<NllLossBackward0>)\n",
      "417 tensor(0.3895, grad_fn=<NllLossBackward0>)\n",
      "418 tensor(0.3894, grad_fn=<NllLossBackward0>)\n",
      "419 tensor(0.3893, grad_fn=<NllLossBackward0>)\n",
      "420 tensor(0.3892, grad_fn=<NllLossBackward0>)\n",
      "421 tensor(0.3891, grad_fn=<NllLossBackward0>)\n",
      "422 tensor(0.3890, grad_fn=<NllLossBackward0>)\n",
      "423 tensor(0.3889, grad_fn=<NllLossBackward0>)\n",
      "424 tensor(0.3888, grad_fn=<NllLossBackward0>)\n",
      "425 tensor(0.3887, grad_fn=<NllLossBackward0>)\n",
      "426 tensor(0.3886, grad_fn=<NllLossBackward0>)\n",
      "427 tensor(0.3885, grad_fn=<NllLossBackward0>)\n",
      "428 tensor(0.3885, grad_fn=<NllLossBackward0>)\n",
      "429 tensor(0.3884, grad_fn=<NllLossBackward0>)\n",
      "430 tensor(0.3883, grad_fn=<NllLossBackward0>)\n",
      "431 tensor(0.3882, grad_fn=<NllLossBackward0>)\n",
      "432 tensor(0.3881, grad_fn=<NllLossBackward0>)\n",
      "433 tensor(0.3881, grad_fn=<NllLossBackward0>)\n",
      "434 tensor(0.3880, grad_fn=<NllLossBackward0>)\n",
      "435 tensor(0.3879, grad_fn=<NllLossBackward0>)\n",
      "436 tensor(0.3879, grad_fn=<NllLossBackward0>)\n",
      "437 tensor(0.3878, grad_fn=<NllLossBackward0>)\n",
      "438 tensor(0.3877, grad_fn=<NllLossBackward0>)\n",
      "439 tensor(0.3876, grad_fn=<NllLossBackward0>)\n",
      "440 tensor(0.3876, grad_fn=<NllLossBackward0>)\n",
      "441 tensor(0.3875, grad_fn=<NllLossBackward0>)\n",
      "442 tensor(0.3875, grad_fn=<NllLossBackward0>)\n",
      "443 tensor(0.3874, grad_fn=<NllLossBackward0>)\n",
      "444 tensor(0.3873, grad_fn=<NllLossBackward0>)\n",
      "445 tensor(0.3873, grad_fn=<NllLossBackward0>)\n",
      "446 tensor(0.3872, grad_fn=<NllLossBackward0>)\n",
      "447 tensor(0.3872, grad_fn=<NllLossBackward0>)\n",
      "448 tensor(0.3871, grad_fn=<NllLossBackward0>)\n",
      "449 tensor(0.3871, grad_fn=<NllLossBackward0>)\n",
      "450 tensor(0.3870, grad_fn=<NllLossBackward0>)\n",
      "451 tensor(0.3870, grad_fn=<NllLossBackward0>)\n",
      "452 tensor(0.3869, grad_fn=<NllLossBackward0>)\n",
      "453 tensor(0.3868, grad_fn=<NllLossBackward0>)\n",
      "454 tensor(0.3868, grad_fn=<NllLossBackward0>)\n",
      "455 tensor(0.3868, grad_fn=<NllLossBackward0>)\n",
      "456 tensor(0.3867, grad_fn=<NllLossBackward0>)\n",
      "457 tensor(0.3867, grad_fn=<NllLossBackward0>)\n",
      "458 tensor(0.3866, grad_fn=<NllLossBackward0>)\n",
      "459 tensor(0.3866, grad_fn=<NllLossBackward0>)\n",
      "460 tensor(0.3865, grad_fn=<NllLossBackward0>)\n",
      "461 tensor(0.3865, grad_fn=<NllLossBackward0>)\n",
      "462 tensor(0.3864, grad_fn=<NllLossBackward0>)\n",
      "463 tensor(0.3864, grad_fn=<NllLossBackward0>)\n",
      "464 tensor(0.3864, grad_fn=<NllLossBackward0>)\n",
      "465 tensor(0.3863, grad_fn=<NllLossBackward0>)\n",
      "466 tensor(0.3863, grad_fn=<NllLossBackward0>)\n",
      "467 tensor(0.3862, grad_fn=<NllLossBackward0>)\n",
      "468 tensor(0.3862, grad_fn=<NllLossBackward0>)\n",
      "469 tensor(0.3862, grad_fn=<NllLossBackward0>)\n",
      "470 tensor(0.3861, grad_fn=<NllLossBackward0>)\n",
      "471 tensor(0.3861, grad_fn=<NllLossBackward0>)\n",
      "472 tensor(0.3861, grad_fn=<NllLossBackward0>)\n",
      "473 tensor(0.3860, grad_fn=<NllLossBackward0>)\n",
      "474 tensor(0.3860, grad_fn=<NllLossBackward0>)\n",
      "475 tensor(0.3859, grad_fn=<NllLossBackward0>)\n",
      "476 tensor(0.3859, grad_fn=<NllLossBackward0>)\n",
      "477 tensor(0.3859, grad_fn=<NllLossBackward0>)\n",
      "478 tensor(0.3858, grad_fn=<NllLossBackward0>)\n",
      "479 tensor(0.3858, grad_fn=<NllLossBackward0>)\n",
      "480 tensor(0.3858, grad_fn=<NllLossBackward0>)\n",
      "481 tensor(0.3857, grad_fn=<NllLossBackward0>)\n",
      "482 tensor(0.3857, grad_fn=<NllLossBackward0>)\n",
      "483 tensor(0.3857, grad_fn=<NllLossBackward0>)\n",
      "484 tensor(0.3857, grad_fn=<NllLossBackward0>)\n",
      "485 tensor(0.3856, grad_fn=<NllLossBackward0>)\n",
      "486 tensor(0.3855, grad_fn=<NllLossBackward0>)\n",
      "487 tensor(0.3854, grad_fn=<NllLossBackward0>)\n",
      "488 tensor(0.3852, grad_fn=<NllLossBackward0>)\n",
      "489 tensor(0.3851, grad_fn=<NllLossBackward0>)\n",
      "490 tensor(0.3849, grad_fn=<NllLossBackward0>)\n",
      "491 tensor(0.3848, grad_fn=<NllLossBackward0>)\n",
      "492 tensor(0.3846, grad_fn=<NllLossBackward0>)\n",
      "493 tensor(0.3845, grad_fn=<NllLossBackward0>)\n",
      "494 tensor(0.3843, grad_fn=<NllLossBackward0>)\n",
      "495 tensor(0.3842, grad_fn=<NllLossBackward0>)\n",
      "496 tensor(0.3840, grad_fn=<NllLossBackward0>)\n",
      "497 tensor(0.3839, grad_fn=<NllLossBackward0>)\n",
      "498 tensor(0.3838, grad_fn=<NllLossBackward0>)\n",
      "499 tensor(0.3837, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on test set: 0.5214285850524902\n"
     ]
    }
   ],
   "source": [
    "model = model(n_input, n_out)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(G.ndata['feat'])\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(logits, G.ndata['label'][train_mask])\n",
    "    print(epoch, loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(G.ndata['feat'][test_mask])\n",
    "    loss_test = nn.CrossEntropyLoss()(pred, G.ndata['label'][test_mask])\n",
    "accuracy = (pred.argmax(dim=1) == G.ndata['label'][test_mask]).float().mean()\n",
    "print(f\"Accuracy on test set: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42624228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e81803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1627fe14-1c25-4234-b887-8d295589f26a",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"2\"></p>\n",
    "\n",
    "2\\. Решите задачу 1, используя два слоя `dgl.nn.GraphConv` вместо полносвязных слоев `torch.nn.Linear`.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7cabd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model2(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.conv1 = gnn.GraphConv(n_input, n_hidden)\n",
    "        self.conv2 = gnn.GraphConv(n_hidden, n_output)\n",
    "    \n",
    "    def forward(self, G, in_features):\n",
    "        out = F.relu(self.conv1(G, in_features))\n",
    "        out = self.conv2(G, out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f93c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = G.ndata['feat'].shape[1]\n",
    "n_hidden = 16\n",
    "n_out = dataset.num_classes\n",
    "\n",
    "model = model2(n_input, n_hidden, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c7745d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = G.ndata['feat']\n",
    "labels = G.ndata['label']\n",
    "test_mask = G.ndata['train_mask']\n",
    "val_mask = G.ndata['val_mask']\n",
    "train_mask = G.ndata['test_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05af4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9471, grad_fn=<NllLossBackward0>)\n",
      "1 tensor(1.9378, grad_fn=<NllLossBackward0>)\n",
      "2 tensor(1.9288, grad_fn=<NllLossBackward0>)\n",
      "3 tensor(1.9186, grad_fn=<NllLossBackward0>)\n",
      "4 tensor(1.9073, grad_fn=<NllLossBackward0>)\n",
      "5 tensor(1.8961, grad_fn=<NllLossBackward0>)\n",
      "6 tensor(1.8840, grad_fn=<NllLossBackward0>)\n",
      "7 tensor(1.8714, grad_fn=<NllLossBackward0>)\n",
      "8 tensor(1.8587, grad_fn=<NllLossBackward0>)\n",
      "9 tensor(1.8452, grad_fn=<NllLossBackward0>)\n",
      "10 tensor(1.8313, grad_fn=<NllLossBackward0>)\n",
      "11 tensor(1.8171, grad_fn=<NllLossBackward0>)\n",
      "12 tensor(1.8019, grad_fn=<NllLossBackward0>)\n",
      "13 tensor(1.7872, grad_fn=<NllLossBackward0>)\n",
      "14 tensor(1.7731, grad_fn=<NllLossBackward0>)\n",
      "15 tensor(1.7586, grad_fn=<NllLossBackward0>)\n",
      "16 tensor(1.7436, grad_fn=<NllLossBackward0>)\n",
      "17 tensor(1.7282, grad_fn=<NllLossBackward0>)\n",
      "18 tensor(1.7128, grad_fn=<NllLossBackward0>)\n",
      "19 tensor(1.6973, grad_fn=<NllLossBackward0>)\n",
      "20 tensor(1.6818, grad_fn=<NllLossBackward0>)\n",
      "21 tensor(1.6660, grad_fn=<NllLossBackward0>)\n",
      "22 tensor(1.6500, grad_fn=<NllLossBackward0>)\n",
      "23 tensor(1.6336, grad_fn=<NllLossBackward0>)\n",
      "24 tensor(1.6169, grad_fn=<NllLossBackward0>)\n",
      "25 tensor(1.5999, grad_fn=<NllLossBackward0>)\n",
      "26 tensor(1.5825, grad_fn=<NllLossBackward0>)\n",
      "27 tensor(1.5648, grad_fn=<NllLossBackward0>)\n",
      "28 tensor(1.5467, grad_fn=<NllLossBackward0>)\n",
      "29 tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "30 tensor(1.5096, grad_fn=<NllLossBackward0>)\n",
      "31 tensor(1.4905, grad_fn=<NllLossBackward0>)\n",
      "32 tensor(1.4711, grad_fn=<NllLossBackward0>)\n",
      "33 tensor(1.4513, grad_fn=<NllLossBackward0>)\n",
      "34 tensor(1.4310, grad_fn=<NllLossBackward0>)\n",
      "35 tensor(1.4101, grad_fn=<NllLossBackward0>)\n",
      "36 tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "37 tensor(1.3666, grad_fn=<NllLossBackward0>)\n",
      "38 tensor(1.3457, grad_fn=<NllLossBackward0>)\n",
      "39 tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
      "40 tensor(1.3030, grad_fn=<NllLossBackward0>)\n",
      "41 tensor(1.2810, grad_fn=<NllLossBackward0>)\n",
      "42 tensor(1.2589, grad_fn=<NllLossBackward0>)\n",
      "43 tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
      "44 tensor(1.2143, grad_fn=<NllLossBackward0>)\n",
      "45 tensor(1.1920, grad_fn=<NllLossBackward0>)\n",
      "46 tensor(1.1695, grad_fn=<NllLossBackward0>)\n",
      "47 tensor(1.1467, grad_fn=<NllLossBackward0>)\n",
      "48 tensor(1.1234, grad_fn=<NllLossBackward0>)\n",
      "49 tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "50 tensor(1.0790, grad_fn=<NllLossBackward0>)\n",
      "51 tensor(1.0572, grad_fn=<NllLossBackward0>)\n",
      "52 tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
      "53 tensor(1.0132, grad_fn=<NllLossBackward0>)\n",
      "54 tensor(0.9913, grad_fn=<NllLossBackward0>)\n",
      "55 tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "56 tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "57 tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "58 tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "59 tensor(0.8867, grad_fn=<NllLossBackward0>)\n",
      "60 tensor(0.8666, grad_fn=<NllLossBackward0>)\n",
      "61 tensor(0.8467, grad_fn=<NllLossBackward0>)\n",
      "62 tensor(0.8272, grad_fn=<NllLossBackward0>)\n",
      "63 tensor(0.8080, grad_fn=<NllLossBackward0>)\n",
      "64 tensor(0.7892, grad_fn=<NllLossBackward0>)\n",
      "65 tensor(0.7707, grad_fn=<NllLossBackward0>)\n",
      "66 tensor(0.7526, grad_fn=<NllLossBackward0>)\n",
      "67 tensor(0.7347, grad_fn=<NllLossBackward0>)\n",
      "68 tensor(0.7173, grad_fn=<NllLossBackward0>)\n",
      "69 tensor(0.7001, grad_fn=<NllLossBackward0>)\n",
      "70 tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
      "71 tensor(0.6669, grad_fn=<NllLossBackward0>)\n",
      "72 tensor(0.6509, grad_fn=<NllLossBackward0>)\n",
      "73 tensor(0.6352, grad_fn=<NllLossBackward0>)\n",
      "74 tensor(0.6198, grad_fn=<NllLossBackward0>)\n",
      "75 tensor(0.6048, grad_fn=<NllLossBackward0>)\n",
      "76 tensor(0.5901, grad_fn=<NllLossBackward0>)\n",
      "77 tensor(0.5758, grad_fn=<NllLossBackward0>)\n",
      "78 tensor(0.5617, grad_fn=<NllLossBackward0>)\n",
      "79 tensor(0.5479, grad_fn=<NllLossBackward0>)\n",
      "80 tensor(0.5342, grad_fn=<NllLossBackward0>)\n",
      "81 tensor(0.5209, grad_fn=<NllLossBackward0>)\n",
      "82 tensor(0.5080, grad_fn=<NllLossBackward0>)\n",
      "83 tensor(0.4956, grad_fn=<NllLossBackward0>)\n",
      "84 tensor(0.4834, grad_fn=<NllLossBackward0>)\n",
      "85 tensor(0.4716, grad_fn=<NllLossBackward0>)\n",
      "86 tensor(0.4601, grad_fn=<NllLossBackward0>)\n",
      "87 tensor(0.4489, grad_fn=<NllLossBackward0>)\n",
      "88 tensor(0.4381, grad_fn=<NllLossBackward0>)\n",
      "89 tensor(0.4275, grad_fn=<NllLossBackward0>)\n",
      "90 tensor(0.4173, grad_fn=<NllLossBackward0>)\n",
      "91 tensor(0.4074, grad_fn=<NllLossBackward0>)\n",
      "92 tensor(0.3978, grad_fn=<NllLossBackward0>)\n",
      "93 tensor(0.3885, grad_fn=<NllLossBackward0>)\n",
      "94 tensor(0.3795, grad_fn=<NllLossBackward0>)\n",
      "95 tensor(0.3708, grad_fn=<NllLossBackward0>)\n",
      "96 tensor(0.3624, grad_fn=<NllLossBackward0>)\n",
      "97 tensor(0.3543, grad_fn=<NllLossBackward0>)\n",
      "98 tensor(0.3464, grad_fn=<NllLossBackward0>)\n",
      "99 tensor(0.3388, grad_fn=<NllLossBackward0>)\n",
      "100 tensor(0.3314, grad_fn=<NllLossBackward0>)\n",
      "101 tensor(0.3243, grad_fn=<NllLossBackward0>)\n",
      "102 tensor(0.3174, grad_fn=<NllLossBackward0>)\n",
      "103 tensor(0.3108, grad_fn=<NllLossBackward0>)\n",
      "104 tensor(0.3044, grad_fn=<NllLossBackward0>)\n",
      "105 tensor(0.2981, grad_fn=<NllLossBackward0>)\n",
      "106 tensor(0.2921, grad_fn=<NllLossBackward0>)\n",
      "107 tensor(0.2863, grad_fn=<NllLossBackward0>)\n",
      "108 tensor(0.2807, grad_fn=<NllLossBackward0>)\n",
      "109 tensor(0.2753, grad_fn=<NllLossBackward0>)\n",
      "110 tensor(0.2700, grad_fn=<NllLossBackward0>)\n",
      "111 tensor(0.2649, grad_fn=<NllLossBackward0>)\n",
      "112 tensor(0.2600, grad_fn=<NllLossBackward0>)\n",
      "113 tensor(0.2552, grad_fn=<NllLossBackward0>)\n",
      "114 tensor(0.2506, grad_fn=<NllLossBackward0>)\n",
      "115 tensor(0.2462, grad_fn=<NllLossBackward0>)\n",
      "116 tensor(0.2418, grad_fn=<NllLossBackward0>)\n",
      "117 tensor(0.2376, grad_fn=<NllLossBackward0>)\n",
      "118 tensor(0.2336, grad_fn=<NllLossBackward0>)\n",
      "119 tensor(0.2296, grad_fn=<NllLossBackward0>)\n",
      "120 tensor(0.2258, grad_fn=<NllLossBackward0>)\n",
      "121 tensor(0.2220, grad_fn=<NllLossBackward0>)\n",
      "122 tensor(0.2184, grad_fn=<NllLossBackward0>)\n",
      "123 tensor(0.2149, grad_fn=<NllLossBackward0>)\n",
      "124 tensor(0.2115, grad_fn=<NllLossBackward0>)\n",
      "125 tensor(0.2082, grad_fn=<NllLossBackward0>)\n",
      "126 tensor(0.2049, grad_fn=<NllLossBackward0>)\n",
      "127 tensor(0.2018, grad_fn=<NllLossBackward0>)\n",
      "128 tensor(0.1987, grad_fn=<NllLossBackward0>)\n",
      "129 tensor(0.1958, grad_fn=<NllLossBackward0>)\n",
      "130 tensor(0.1929, grad_fn=<NllLossBackward0>)\n",
      "131 tensor(0.1900, grad_fn=<NllLossBackward0>)\n",
      "132 tensor(0.1873, grad_fn=<NllLossBackward0>)\n",
      "133 tensor(0.1846, grad_fn=<NllLossBackward0>)\n",
      "134 tensor(0.1820, grad_fn=<NllLossBackward0>)\n",
      "135 tensor(0.1794, grad_fn=<NllLossBackward0>)\n",
      "136 tensor(0.1770, grad_fn=<NllLossBackward0>)\n",
      "137 tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "138 tensor(0.1722, grad_fn=<NllLossBackward0>)\n",
      "139 tensor(0.1698, grad_fn=<NllLossBackward0>)\n",
      "140 tensor(0.1676, grad_fn=<NllLossBackward0>)\n",
      "141 tensor(0.1654, grad_fn=<NllLossBackward0>)\n",
      "142 tensor(0.1632, grad_fn=<NllLossBackward0>)\n",
      "143 tensor(0.1611, grad_fn=<NllLossBackward0>)\n",
      "144 tensor(0.1590, grad_fn=<NllLossBackward0>)\n",
      "145 tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "146 tensor(0.1550, grad_fn=<NllLossBackward0>)\n",
      "147 tensor(0.1531, grad_fn=<NllLossBackward0>)\n",
      "148 tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
      "149 tensor(0.1493, grad_fn=<NllLossBackward0>)\n",
      "150 tensor(0.1475, grad_fn=<NllLossBackward0>)\n",
      "151 tensor(0.1457, grad_fn=<NllLossBackward0>)\n",
      "152 tensor(0.1440, grad_fn=<NllLossBackward0>)\n",
      "153 tensor(0.1423, grad_fn=<NllLossBackward0>)\n",
      "154 tensor(0.1406, grad_fn=<NllLossBackward0>)\n",
      "155 tensor(0.1390, grad_fn=<NllLossBackward0>)\n",
      "156 tensor(0.1373, grad_fn=<NllLossBackward0>)\n",
      "157 tensor(0.1358, grad_fn=<NllLossBackward0>)\n",
      "158 tensor(0.1342, grad_fn=<NllLossBackward0>)\n",
      "159 tensor(0.1327, grad_fn=<NllLossBackward0>)\n",
      "160 tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
      "161 tensor(0.1298, grad_fn=<NllLossBackward0>)\n",
      "162 tensor(0.1283, grad_fn=<NllLossBackward0>)\n",
      "163 tensor(0.1269, grad_fn=<NllLossBackward0>)\n",
      "164 tensor(0.1255, grad_fn=<NllLossBackward0>)\n",
      "165 tensor(0.1242, grad_fn=<NllLossBackward0>)\n",
      "166 tensor(0.1228, grad_fn=<NllLossBackward0>)\n",
      "167 tensor(0.1215, grad_fn=<NllLossBackward0>)\n",
      "168 tensor(0.1203, grad_fn=<NllLossBackward0>)\n",
      "169 tensor(0.1190, grad_fn=<NllLossBackward0>)\n",
      "170 tensor(0.1178, grad_fn=<NllLossBackward0>)\n",
      "171 tensor(0.1165, grad_fn=<NllLossBackward0>)\n",
      "172 tensor(0.1153, grad_fn=<NllLossBackward0>)\n",
      "173 tensor(0.1142, grad_fn=<NllLossBackward0>)\n",
      "174 tensor(0.1130, grad_fn=<NllLossBackward0>)\n",
      "175 tensor(0.1119, grad_fn=<NllLossBackward0>)\n",
      "176 tensor(0.1107, grad_fn=<NllLossBackward0>)\n",
      "177 tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "178 tensor(0.1086, grad_fn=<NllLossBackward0>)\n",
      "179 tensor(0.1075, grad_fn=<NllLossBackward0>)\n",
      "180 tensor(0.1064, grad_fn=<NllLossBackward0>)\n",
      "181 tensor(0.1054, grad_fn=<NllLossBackward0>)\n",
      "182 tensor(0.1044, grad_fn=<NllLossBackward0>)\n",
      "183 tensor(0.1034, grad_fn=<NllLossBackward0>)\n",
      "184 tensor(0.1024, grad_fn=<NllLossBackward0>)\n",
      "185 tensor(0.1014, grad_fn=<NllLossBackward0>)\n",
      "186 tensor(0.1005, grad_fn=<NllLossBackward0>)\n",
      "187 tensor(0.0996, grad_fn=<NllLossBackward0>)\n",
      "188 tensor(0.0986, grad_fn=<NllLossBackward0>)\n",
      "189 tensor(0.0977, grad_fn=<NllLossBackward0>)\n",
      "190 tensor(0.0968, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 tensor(0.0959, grad_fn=<NllLossBackward0>)\n",
      "192 tensor(0.0951, grad_fn=<NllLossBackward0>)\n",
      "193 tensor(0.0942, grad_fn=<NllLossBackward0>)\n",
      "194 tensor(0.0934, grad_fn=<NllLossBackward0>)\n",
      "195 tensor(0.0925, grad_fn=<NllLossBackward0>)\n",
      "196 tensor(0.0917, grad_fn=<NllLossBackward0>)\n",
      "197 tensor(0.0909, grad_fn=<NllLossBackward0>)\n",
      "198 tensor(0.0901, grad_fn=<NllLossBackward0>)\n",
      "199 tensor(0.0893, grad_fn=<NllLossBackward0>)\n",
      "200 tensor(0.0885, grad_fn=<NllLossBackward0>)\n",
      "201 tensor(0.0877, grad_fn=<NllLossBackward0>)\n",
      "202 tensor(0.0870, grad_fn=<NllLossBackward0>)\n",
      "203 tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "204 tensor(0.0855, grad_fn=<NllLossBackward0>)\n",
      "205 tensor(0.0848, grad_fn=<NllLossBackward0>)\n",
      "206 tensor(0.0841, grad_fn=<NllLossBackward0>)\n",
      "207 tensor(0.0834, grad_fn=<NllLossBackward0>)\n",
      "208 tensor(0.0827, grad_fn=<NllLossBackward0>)\n",
      "209 tensor(0.0820, grad_fn=<NllLossBackward0>)\n",
      "210 tensor(0.0813, grad_fn=<NllLossBackward0>)\n",
      "211 tensor(0.0806, grad_fn=<NllLossBackward0>)\n",
      "212 tensor(0.0800, grad_fn=<NllLossBackward0>)\n",
      "213 tensor(0.0793, grad_fn=<NllLossBackward0>)\n",
      "214 tensor(0.0787, grad_fn=<NllLossBackward0>)\n",
      "215 tensor(0.0780, grad_fn=<NllLossBackward0>)\n",
      "216 tensor(0.0774, grad_fn=<NllLossBackward0>)\n",
      "217 tensor(0.0768, grad_fn=<NllLossBackward0>)\n",
      "218 tensor(0.0762, grad_fn=<NllLossBackward0>)\n",
      "219 tensor(0.0756, grad_fn=<NllLossBackward0>)\n",
      "220 tensor(0.0750, grad_fn=<NllLossBackward0>)\n",
      "221 tensor(0.0744, grad_fn=<NllLossBackward0>)\n",
      "222 tensor(0.0738, grad_fn=<NllLossBackward0>)\n",
      "223 tensor(0.0732, grad_fn=<NllLossBackward0>)\n",
      "224 tensor(0.0727, grad_fn=<NllLossBackward0>)\n",
      "225 tensor(0.0721, grad_fn=<NllLossBackward0>)\n",
      "226 tensor(0.0716, grad_fn=<NllLossBackward0>)\n",
      "227 tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "228 tensor(0.0705, grad_fn=<NllLossBackward0>)\n",
      "229 tensor(0.0700, grad_fn=<NllLossBackward0>)\n",
      "230 tensor(0.0694, grad_fn=<NllLossBackward0>)\n",
      "231 tensor(0.0689, grad_fn=<NllLossBackward0>)\n",
      "232 tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
      "233 tensor(0.0679, grad_fn=<NllLossBackward0>)\n",
      "234 tensor(0.0674, grad_fn=<NllLossBackward0>)\n",
      "235 tensor(0.0669, grad_fn=<NllLossBackward0>)\n",
      "236 tensor(0.0664, grad_fn=<NllLossBackward0>)\n",
      "237 tensor(0.0660, grad_fn=<NllLossBackward0>)\n",
      "238 tensor(0.0655, grad_fn=<NllLossBackward0>)\n",
      "239 tensor(0.0650, grad_fn=<NllLossBackward0>)\n",
      "240 tensor(0.0646, grad_fn=<NllLossBackward0>)\n",
      "241 tensor(0.0641, grad_fn=<NllLossBackward0>)\n",
      "242 tensor(0.0636, grad_fn=<NllLossBackward0>)\n",
      "243 tensor(0.0632, grad_fn=<NllLossBackward0>)\n",
      "244 tensor(0.0628, grad_fn=<NllLossBackward0>)\n",
      "245 tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "246 tensor(0.0619, grad_fn=<NllLossBackward0>)\n",
      "247 tensor(0.0615, grad_fn=<NllLossBackward0>)\n",
      "248 tensor(0.0610, grad_fn=<NllLossBackward0>)\n",
      "249 tensor(0.0606, grad_fn=<NllLossBackward0>)\n",
      "250 tensor(0.0602, grad_fn=<NllLossBackward0>)\n",
      "251 tensor(0.0598, grad_fn=<NllLossBackward0>)\n",
      "252 tensor(0.0594, grad_fn=<NllLossBackward0>)\n",
      "253 tensor(0.0590, grad_fn=<NllLossBackward0>)\n",
      "254 tensor(0.0586, grad_fn=<NllLossBackward0>)\n",
      "255 tensor(0.0582, grad_fn=<NllLossBackward0>)\n",
      "256 tensor(0.0578, grad_fn=<NllLossBackward0>)\n",
      "257 tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
      "258 tensor(0.0571, grad_fn=<NllLossBackward0>)\n",
      "259 tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "260 tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
      "261 tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
      "262 tensor(0.0556, grad_fn=<NllLossBackward0>)\n",
      "263 tensor(0.0553, grad_fn=<NllLossBackward0>)\n",
      "264 tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "265 tensor(0.0546, grad_fn=<NllLossBackward0>)\n",
      "266 tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "267 tensor(0.0539, grad_fn=<NllLossBackward0>)\n",
      "268 tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "269 tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "270 tensor(0.0529, grad_fn=<NllLossBackward0>)\n",
      "271 tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
      "272 tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "273 tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "274 tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "275 tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "276 tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "277 tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "278 tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
      "279 tensor(0.0500, grad_fn=<NllLossBackward0>)\n",
      "280 tensor(0.0497, grad_fn=<NllLossBackward0>)\n",
      "281 tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
      "282 tensor(0.0491, grad_fn=<NllLossBackward0>)\n",
      "283 tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "284 tensor(0.0485, grad_fn=<NllLossBackward0>)\n",
      "285 tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "286 tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "287 tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "288 tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "289 tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "290 tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "291 tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "292 tensor(0.0463, grad_fn=<NllLossBackward0>)\n",
      "293 tensor(0.0461, grad_fn=<NllLossBackward0>)\n",
      "294 tensor(0.0458, grad_fn=<NllLossBackward0>)\n",
      "295 tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "296 tensor(0.0453, grad_fn=<NllLossBackward0>)\n",
      "297 tensor(0.0450, grad_fn=<NllLossBackward0>)\n",
      "298 tensor(0.0448, grad_fn=<NllLossBackward0>)\n",
      "299 tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "300 tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "301 tensor(0.0440, grad_fn=<NllLossBackward0>)\n",
      "302 tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "303 tensor(0.0436, grad_fn=<NllLossBackward0>)\n",
      "304 tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "305 tensor(0.0431, grad_fn=<NllLossBackward0>)\n",
      "306 tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "307 tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
      "308 tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
      "309 tensor(0.0422, grad_fn=<NllLossBackward0>)\n",
      "310 tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "311 tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "312 tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
      "313 tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "314 tensor(0.0410, grad_fn=<NllLossBackward0>)\n",
      "315 tensor(0.0408, grad_fn=<NllLossBackward0>)\n",
      "316 tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "317 tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "318 tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "319 tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "320 tensor(0.0398, grad_fn=<NllLossBackward0>)\n",
      "321 tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
      "322 tensor(0.0394, grad_fn=<NllLossBackward0>)\n",
      "323 tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "324 tensor(0.0390, grad_fn=<NllLossBackward0>)\n",
      "325 tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
      "326 tensor(0.0386, grad_fn=<NllLossBackward0>)\n",
      "327 tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "328 tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
      "329 tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "330 tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "331 tensor(0.0376, grad_fn=<NllLossBackward0>)\n",
      "332 tensor(0.0374, grad_fn=<NllLossBackward0>)\n",
      "333 tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "334 tensor(0.0370, grad_fn=<NllLossBackward0>)\n",
      "335 tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "336 tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "337 tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "338 tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
      "339 tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
      "340 tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
      "341 tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "342 tensor(0.0356, grad_fn=<NllLossBackward0>)\n",
      "343 tensor(0.0354, grad_fn=<NllLossBackward0>)\n",
      "344 tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
      "345 tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "346 tensor(0.0349, grad_fn=<NllLossBackward0>)\n",
      "347 tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
      "348 tensor(0.0346, grad_fn=<NllLossBackward0>)\n",
      "349 tensor(0.0344, grad_fn=<NllLossBackward0>)\n",
      "350 tensor(0.0343, grad_fn=<NllLossBackward0>)\n",
      "351 tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "352 tensor(0.0340, grad_fn=<NllLossBackward0>)\n",
      "353 tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "354 tensor(0.0336, grad_fn=<NllLossBackward0>)\n",
      "355 tensor(0.0335, grad_fn=<NllLossBackward0>)\n",
      "356 tensor(0.0333, grad_fn=<NllLossBackward0>)\n",
      "357 tensor(0.0332, grad_fn=<NllLossBackward0>)\n",
      "358 tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
      "359 tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
      "360 tensor(0.0327, grad_fn=<NllLossBackward0>)\n",
      "361 tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "362 tensor(0.0324, grad_fn=<NllLossBackward0>)\n",
      "363 tensor(0.0323, grad_fn=<NllLossBackward0>)\n",
      "364 tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "365 tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "366 tensor(0.0318, grad_fn=<NllLossBackward0>)\n",
      "367 tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "368 tensor(0.0316, grad_fn=<NllLossBackward0>)\n",
      "369 tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
      "370 tensor(0.0313, grad_fn=<NllLossBackward0>)\n",
      "371 tensor(0.0311, grad_fn=<NllLossBackward0>)\n",
      "372 tensor(0.0310, grad_fn=<NllLossBackward0>)\n",
      "373 tensor(0.0309, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 tensor(0.0307, grad_fn=<NllLossBackward0>)\n",
      "375 tensor(0.0306, grad_fn=<NllLossBackward0>)\n",
      "376 tensor(0.0305, grad_fn=<NllLossBackward0>)\n",
      "377 tensor(0.0303, grad_fn=<NllLossBackward0>)\n",
      "378 tensor(0.0302, grad_fn=<NllLossBackward0>)\n",
      "379 tensor(0.0301, grad_fn=<NllLossBackward0>)\n",
      "380 tensor(0.0299, grad_fn=<NllLossBackward0>)\n",
      "381 tensor(0.0298, grad_fn=<NllLossBackward0>)\n",
      "382 tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
      "383 tensor(0.0296, grad_fn=<NllLossBackward0>)\n",
      "384 tensor(0.0294, grad_fn=<NllLossBackward0>)\n",
      "385 tensor(0.0293, grad_fn=<NllLossBackward0>)\n",
      "386 tensor(0.0292, grad_fn=<NllLossBackward0>)\n",
      "387 tensor(0.0291, grad_fn=<NllLossBackward0>)\n",
      "388 tensor(0.0289, grad_fn=<NllLossBackward0>)\n",
      "389 tensor(0.0288, grad_fn=<NllLossBackward0>)\n",
      "390 tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
      "391 tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
      "392 tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "393 tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
      "394 tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
      "395 tensor(0.0281, grad_fn=<NllLossBackward0>)\n",
      "396 tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "397 tensor(0.0279, grad_fn=<NllLossBackward0>)\n",
      "398 tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
      "399 tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
      "400 tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
      "401 tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
      "402 tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
      "403 tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
      "404 tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
      "405 tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
      "406 tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
      "407 tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
      "408 tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
      "409 tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
      "410 tensor(0.0265, grad_fn=<NllLossBackward0>)\n",
      "411 tensor(0.0264, grad_fn=<NllLossBackward0>)\n",
      "412 tensor(0.0263, grad_fn=<NllLossBackward0>)\n",
      "413 tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
      "414 tensor(0.0261, grad_fn=<NllLossBackward0>)\n",
      "415 tensor(0.0260, grad_fn=<NllLossBackward0>)\n",
      "416 tensor(0.0259, grad_fn=<NllLossBackward0>)\n",
      "417 tensor(0.0258, grad_fn=<NllLossBackward0>)\n",
      "418 tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "419 tensor(0.0256, grad_fn=<NllLossBackward0>)\n",
      "420 tensor(0.0255, grad_fn=<NllLossBackward0>)\n",
      "421 tensor(0.0254, grad_fn=<NllLossBackward0>)\n",
      "422 tensor(0.0253, grad_fn=<NllLossBackward0>)\n",
      "423 tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "424 tensor(0.0251, grad_fn=<NllLossBackward0>)\n",
      "425 tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "426 tensor(0.0249, grad_fn=<NllLossBackward0>)\n",
      "427 tensor(0.0248, grad_fn=<NllLossBackward0>)\n",
      "428 tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
      "429 tensor(0.0246, grad_fn=<NllLossBackward0>)\n",
      "430 tensor(0.0246, grad_fn=<NllLossBackward0>)\n",
      "431 tensor(0.0245, grad_fn=<NllLossBackward0>)\n",
      "432 tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "433 tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
      "434 tensor(0.0242, grad_fn=<NllLossBackward0>)\n",
      "435 tensor(0.0241, grad_fn=<NllLossBackward0>)\n",
      "436 tensor(0.0240, grad_fn=<NllLossBackward0>)\n",
      "437 tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
      "438 tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
      "439 tensor(0.0238, grad_fn=<NllLossBackward0>)\n",
      "440 tensor(0.0237, grad_fn=<NllLossBackward0>)\n",
      "441 tensor(0.0236, grad_fn=<NllLossBackward0>)\n",
      "442 tensor(0.0235, grad_fn=<NllLossBackward0>)\n",
      "443 tensor(0.0234, grad_fn=<NllLossBackward0>)\n",
      "444 tensor(0.0234, grad_fn=<NllLossBackward0>)\n",
      "445 tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
      "446 tensor(0.0232, grad_fn=<NllLossBackward0>)\n",
      "447 tensor(0.0231, grad_fn=<NllLossBackward0>)\n",
      "448 tensor(0.0230, grad_fn=<NllLossBackward0>)\n",
      "449 tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
      "450 tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
      "451 tensor(0.0228, grad_fn=<NllLossBackward0>)\n",
      "452 tensor(0.0227, grad_fn=<NllLossBackward0>)\n",
      "453 tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "454 tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "455 tensor(0.0225, grad_fn=<NllLossBackward0>)\n",
      "456 tensor(0.0224, grad_fn=<NllLossBackward0>)\n",
      "457 tensor(0.0223, grad_fn=<NllLossBackward0>)\n",
      "458 tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
      "459 tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
      "460 tensor(0.0221, grad_fn=<NllLossBackward0>)\n",
      "461 tensor(0.0220, grad_fn=<NllLossBackward0>)\n",
      "462 tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "463 tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "464 tensor(0.0218, grad_fn=<NllLossBackward0>)\n",
      "465 tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "466 tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "467 tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
      "468 tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
      "469 tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "470 tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "471 tensor(0.0213, grad_fn=<NllLossBackward0>)\n",
      "472 tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "473 tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "474 tensor(0.0211, grad_fn=<NllLossBackward0>)\n",
      "475 tensor(0.0210, grad_fn=<NllLossBackward0>)\n",
      "476 tensor(0.0210, grad_fn=<NllLossBackward0>)\n",
      "477 tensor(0.0209, grad_fn=<NllLossBackward0>)\n",
      "478 tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "479 tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "480 tensor(0.0207, grad_fn=<NllLossBackward0>)\n",
      "481 tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
      "482 tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
      "483 tensor(0.0205, grad_fn=<NllLossBackward0>)\n",
      "484 tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "485 tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "486 tensor(0.0203, grad_fn=<NllLossBackward0>)\n",
      "487 tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
      "488 tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
      "489 tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
      "490 tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
      "491 tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
      "492 tensor(0.0199, grad_fn=<NllLossBackward0>)\n",
      "493 tensor(0.0199, grad_fn=<NllLossBackward0>)\n",
      "494 tensor(0.0198, grad_fn=<NllLossBackward0>)\n",
      "495 tensor(0.0197, grad_fn=<NllLossBackward0>)\n",
      "496 tensor(0.0197, grad_fn=<NllLossBackward0>)\n",
      "497 tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "498 tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "499 tensor(0.0195, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on test set: 0.8428571224212646\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(G, features)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(logits[train_mask], G.ndata['label'][train_mask])\n",
    "    print(epoch, loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(G, features)\n",
    "    loss_test = nn.CrossEntropyLoss()(pred[test_mask], G.ndata['label'][test_mask])\n",
    "accuracy = (pred[test_mask].argmax(dim=1) == G.ndata['label'][test_mask]).float().mean()\n",
    "print(f\"Accuracy on test set: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845f995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661ad10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17c159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e349d5-0e05-436b-9ecd-badbd2844fa4",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"3\"></p>\n",
    "\n",
    "3\\. Воспользовавшись необученной моделью из предыдущего задания, получите прогнозы для всех узлов графа. Уменьшите размерность полученных прогнозов до 2 при помощи алгоритма t-SNE (`sklearn.manifold.TSNE`). Визуализируйте точки на плоскости, используя полученные значения в качестве координат. Раскрасьте точки в цвета, соответствующим меткам узлов. \n",
    "\n",
    "Повторите данную процедуру, используя обученную модель. Сравните результаты и сделайте выводы.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b400c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "520e63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.manifold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e5f03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c={0: 'red', 1:'green', 2: 'pink', 3:'blue', 4:'orange', 5:'black', 6:'yellow'}\n",
    "col=[]\n",
    "for i in torch.argmax(pred, dim=1):\n",
    "    col.append(c[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5367a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model2(n_input, n_hidden, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4ab0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(G, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "453007f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elena\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elena\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_2 =sklearn.manifold.TSNE(n_components=2).fit_transform(pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77d6cb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24df4307520>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pred_2[:, 0], pred_2[:, 1], color=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3142f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b27ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "594aa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "c={0: 'red', 1:'green', 2: 'pink', 3:'blue', 4:'orange', 5:'black', 6:'yellow'}\n",
    "col=[]\n",
    "for i in torch.argmax(pred, dim=1):\n",
    "    col.append(c[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03e5cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elena\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elena\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24df4399df0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model\n",
    "\n",
    "pred = model(G, features)\n",
    "\n",
    "pred_2 =sklearn.manifold.TSNE(n_components=2).fit_transform(pred.detach().numpy())\n",
    "\n",
    "plt.scatter(pred_2[:, 0], pred_2[:, 1], color=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf9392-8ee3-45c2-b462-f2f8a9ceb9ca",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"4\"></p>\n",
    "\n",
    "4\\.  Предыдущие решения не используют узлы, находящиеся в валидационном множестве. Решите задачу 2, используя валидационное множество для выполнения ранней остановки.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b938164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loss_function):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output = model(G, features)\n",
    "    loss = loss_function(logits[val_mask], G.ndata['label'][val_mask])\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "750512dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = G.ndata['feat'].shape[1]\n",
    "n_hidden = 16\n",
    "n_out = dataset.num_classes\n",
    "\n",
    "model = model2(n_input, n_hidden, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b5dcbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9460, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.9460, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0460, grad_fn=<SubBackward0>)\n",
      "1 tensor(1.9335, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.9333, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0127, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "2 tensor(1.9199, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.9200, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0133, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "3 tensor(1.9050, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.9054, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0146, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "4 tensor(1.8898, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.8907, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0147, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "5 tensor(1.8746, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.8761, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0145, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "6 tensor(1.8591, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.8613, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0149, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "7 tensor(1.8432, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.8461, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0152, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "8 tensor(1.8269, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.8306, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0154, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "9 tensor(1.8101, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.8149, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0157, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "10 tensor(1.7933, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7992, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0157, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "11 tensor(1.7770, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7842, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0151, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "12 tensor(1.7612, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7699, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0143, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "13 tensor(1.7462, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7564, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0135, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "14 tensor(1.7313, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7431, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0133, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "15 tensor(1.7162, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7297, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0134, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "16 tensor(1.7009, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7161, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0136, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "17 tensor(1.6858, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.7025, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0135, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "18 tensor(1.6707, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.6889, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0136, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "19 tensor(1.6552, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.6749, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0140, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "20 tensor(1.6391, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.6603, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0146, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "21 tensor(1.6225, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.6451, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0152, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "22 tensor(1.6053, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.6293, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0158, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "23 tensor(1.5874, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.6128, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0164, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "24 tensor(1.5689, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.5958, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0170, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "25 tensor(1.5498, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.5783, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0175, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "26 tensor(1.5303, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.5605, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0178, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "27 tensor(1.5105, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.5424, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0181, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "28 tensor(1.4903, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.5240, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0183, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "29 tensor(1.4697, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.5055, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0186, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "30 tensor(1.4489, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.4867, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0188, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "31 tensor(1.4279, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.4678, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0189, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "32 tensor(1.4066, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.4488, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0190, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "33 tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.4296, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0191, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "34 tensor(1.3635, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.4105, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0191, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "35 tensor(1.3419, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.3913, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0192, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "36 tensor(1.3201, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.3721, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0192, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "37 tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.3528, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0193, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "38 tensor(1.2761, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0193, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "39 tensor(1.2539, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.3141, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0193, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "40 tensor(1.2316, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.2948, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0193, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "41 tensor(1.2093, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.2756, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0193, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "42 tensor(1.1870, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0192, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "43 tensor(1.1647, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.2373, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0191, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "44 tensor(1.1425, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.2183, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0190, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "45 tensor(1.1204, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.1994, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0189, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "46 tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.1807, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0187, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "47 tensor(1.0765, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.1621, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0186, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "48 tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.1437, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0184, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "49 tensor(1.0331, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.1254, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0183, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "50 tensor(1.0117, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.1073, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0181, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "51 tensor(0.9905, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.0894, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0179, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "52 tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.0717, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0177, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "53 tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0175, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "54 tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.0369, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0173, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "55 tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.0198, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0171, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "56 tensor(0.8874, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0168, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 tensor(0.8675, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.9866, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0165, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "58 tensor(0.8480, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.9705, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0161, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "59 tensor(0.8287, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0158, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "60 tensor(0.8098, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0154, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "61 tensor(0.7912, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0150, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "62 tensor(0.7729, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0146, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "63 tensor(0.7550, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8955, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0142, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "64 tensor(0.7374, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8817, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0138, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "65 tensor(0.7202, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8682, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0134, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "66 tensor(0.7034, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8551, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0131, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "67 tensor(0.6869, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8425, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0127, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "68 tensor(0.6708, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8302, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0123, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "69 tensor(0.6550, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8182, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0119, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "70 tensor(0.6396, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.8067, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0116, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "71 tensor(0.6246, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7954, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0112, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "72 tensor(0.6100, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7845, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0109, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "73 tensor(0.5957, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7740, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0106, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "74 tensor(0.5818, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7637, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0102, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "75 tensor(0.5683, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7538, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0099, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "76 tensor(0.5551, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7442, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0096, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "77 tensor(0.5423, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7349, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0093, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "78 tensor(0.5299, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7260, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0090, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "79 tensor(0.5178, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7173, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0086, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "80 tensor(0.5061, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7090, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0083, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "81 tensor(0.4947, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.7010, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0080, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "82 tensor(0.4836, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6933, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0077, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "83 tensor(0.4729, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0074, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "84 tensor(0.4625, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6788, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0071, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "85 tensor(0.4525, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6720, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0068, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "86 tensor(0.4427, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6655, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0065, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "87 tensor(0.4333, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6593, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0062, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "88 tensor(0.4241, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6534, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0059, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "89 tensor(0.4153, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6477, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0057, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "90 tensor(0.4067, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6423, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0054, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "91 tensor(0.3984, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6371, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0052, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "92 tensor(0.3903, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6322, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0049, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "93 tensor(0.3826, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6274, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0047, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "94 tensor(0.3750, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6229, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0045, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "95 tensor(0.3677, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6186, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0043, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "96 tensor(0.3607, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6145, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0041, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "97 tensor(0.3538, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6106, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0039, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "98 tensor(0.3472, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6069, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0037, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "99 tensor(0.3408, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.6033, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0036, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "100 tensor(0.3345, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5999, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0034, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "101 tensor(0.3285, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5967, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0032, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "102 tensor(0.3227, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5936, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0031, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "103 tensor(0.3170, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5907, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0029, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "104 tensor(0.3115, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5879, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0028, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "105 tensor(0.3062, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5853, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0027, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "106 tensor(0.3011, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0025, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "107 tensor(0.2961, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.5804, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0024, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "108 tensor(0.2912, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5781, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0023, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "109 tensor(0.2865, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5759, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0022, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "110 tensor(0.2819, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5738, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0021, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "111 tensor(0.2775, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5718, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0020, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "112 tensor(0.2732, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5700, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0019, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "113 tensor(0.2690, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5682, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0018, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "114 tensor(0.2649, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5665, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0017, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "115 tensor(0.2609, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5649, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0016, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "116 tensor(0.2571, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5634, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0015, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "117 tensor(0.2534, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5619, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0014, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "118 tensor(0.2497, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5606, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0014, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "119 tensor(0.2462, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5593, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0013, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "120 tensor(0.2427, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5581, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0012, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "121 tensor(0.2393, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0012, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "122 tensor(0.2361, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5558, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0011, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "123 tensor(0.2329, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5548, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0010, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "124 tensor(0.2298, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0010, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "125 tensor(0.2267, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5529, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0009, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "126 tensor(0.2238, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5520, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0009, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "127 tensor(0.2209, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5512, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0008, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "128 tensor(0.2180, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5504, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0008, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "129 tensor(0.2153, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5497, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0007, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "130 tensor(0.2126, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5490, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0007, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "131 tensor(0.2100, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5484, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0006, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "132 tensor(0.2074, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5478, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0006, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "133 tensor(0.2049, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5472, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0006, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "134 tensor(0.2024, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5467, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0005, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "135 tensor(0.2000, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5462, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0005, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "136 tensor(0.1977, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5458, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0004, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "137 tensor(0.1954, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0004, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "138 tensor(0.1931, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5450, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0004, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "139 tensor(0.1909, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5447, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0003, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "140 tensor(0.1888, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5443, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0003, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "141 tensor(0.1867, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5441, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0003, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "142 tensor(0.1846, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5438, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0003, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "143 tensor(0.1826, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5436, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "144 tensor(0.1806, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5434, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "145 tensor(0.1786, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5432, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "146 tensor(0.1767, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5431, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0001, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "147 tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5430, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-0.0001, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "148 tensor(0.1730, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5429, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-8.6129e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "149 tensor(0.1712, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-6.3300e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "150 tensor(0.1694, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-4.5955e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "151 tensor(0.1677, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5427, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-3.5644e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "152 tensor(0.1660, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5427, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-3.2067e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "153 tensor(0.1643, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5427, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(-2.0742e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "154 tensor(0.1627, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5427, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(2.3246e-06, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 tensor(0.1610, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5427, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(2.5749e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "156 tensor(0.1595, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5427, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(5.0068e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "157 tensor(0.1579, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(6.6936e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "158 tensor(0.1564, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5429, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(7.8499e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "159 tensor(0.1548, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5430, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(9.4771e-05, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "160 tensor(0.1534, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5431, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "161 tensor(0.1519, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5432, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "162 tensor(0.1505, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5433, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "163 tensor(0.1490, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5435, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "164 tensor(0.1477, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5437, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "165 tensor(0.1463, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5438, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "166 tensor(0.1449, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5440, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "trigger times: 0\n",
      "167 tensor(0.1436, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5442, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "168 tensor(0.1423, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5445, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "169 tensor(0.1410, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5447, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "170 tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5449, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "171 tensor(0.1385, grad_fn=<NllLossBackward0>)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "!!!!!! tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Accuracy on test set: 0.8785714507102966\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 500\n",
    "patience=5\n",
    "trigger_times = 0\n",
    "last_loss=1.9\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(G, features)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(logits[train_mask], G.ndata['label'][train_mask])\n",
    "#     last_loss=loss\n",
    "    print(epoch, loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    current_loss = validation(model,  nn.CrossEntropyLoss())\n",
    "    print('The Current Loss:', current_loss)\n",
    "#     print('!!!!!!', current_loss - last_loss)\n",
    "    if (current_loss - last_loss) > 0.0002:\n",
    "            trigger_times += 1\n",
    "            last_loss = current_loss\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "\n",
    "    else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "            last_loss = current_loss\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(G, features)\n",
    "    loss_test = nn.CrossEntropyLoss()(pred[test_mask], G.ndata['label'][test_mask])\n",
    "accuracy = (pred[test_mask].argmax(dim=1) == G.ndata['label'][test_mask]).float().mean()\n",
    "print(f\"Accuracy on test set: {accuracy.item()}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda9674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1764ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd85a863-f864-4b7f-b88c-f96c469cbd3c",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"5\"></p>\n",
    "\n",
    "5\\. Повторите решение задачи 4, сравнив несколько различных слоев:\n",
    "* GraphConv\n",
    "* SAGEConv (укажите `aggregator_type=\"mean\"`)\n",
    "* GATConv (выберите для первого слоя `num_heads > 1`)\n",
    "\n",
    "Выведите результат в виде таблицы:\n",
    "\n",
    "| Модель    | Loss на обучении | Acc на обучении | Acc на тесте | Кол-во эпох до ранней остановки |\n",
    "|-----------|------------------|-----------------|--------------|-------------|\n",
    "| GraphConv |                  |                 |              |             |\n",
    "| SAGEConv  |                  |                 |              |             |\n",
    "| GATConv   |                  |                 |              |             |\n",
    "\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9b773b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.conv1 = gnn.GraphConv(n_input, n_hidden)\n",
    "        self.conv2 = gnn.GraphConv(n_hidden, n_output)\n",
    "    \n",
    "    def forward(self, G, in_features):\n",
    "        out = F.relu(self.conv1(G, in_features))\n",
    "        out = self.conv2(G, out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dfebdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConv(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.conv1 = gnn.SAGEConv(n_input, n_hidden, aggregator_type=\"mean\")\n",
    "        self.conv2 = gnn.SAGEConv(n_hidden, n_output, aggregator_type=\"mean\")\n",
    "    \n",
    "    def forward(self, G, in_features):\n",
    "        out = F.relu(self.conv1(G, in_features))\n",
    "        out = self.conv2(G, out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1db23307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATConv(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.conv1 = gnn.GATConv(n_input, n_hidden, num_heads = 3)\n",
    "        self.conv2 = gnn.GATConv(n_hidden, n_output, num_heads = 3 )\n",
    "    \n",
    "    def forward(self, G, in_features):\n",
    "        out = F.relu(self.conv1(G, in_features))\n",
    "        out = self.conv2(G, out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b2faae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = G.ndata['feat'].shape[1]\n",
    "n_hidden = 16\n",
    "n_out = dataset.num_classes\n",
    "\n",
    "model = GraphConv(n_input, n_hidden, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4969bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9474, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1010)\n",
      "The Current Loss: tensor(1.9473, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "1 tensor(1.9375, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.9372, grad_fn=<NllLossBackward0>)\n",
      "1\n",
      "trigger times: 0\n",
      "2 tensor(1.9283, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.9280, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "3 tensor(1.9179, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.9179, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "4 tensor(1.9072, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.9075, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "5 tensor(1.8963, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8970, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "6 tensor(1.8848, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8860, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "7 tensor(1.8729, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8744, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "8 tensor(1.8604, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8624, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "9 tensor(1.8477, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8503, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "10 tensor(1.8349, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8382, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "11 tensor(1.8221, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8260, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "12 tensor(1.8095, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8143, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "13 tensor(1.7972, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.8029, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "14 tensor(1.7849, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7916, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "15 tensor(1.7729, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7806, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "16 tensor(1.7610, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7698, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "17 tensor(1.7491, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7592, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "18 tensor(1.7372, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7485, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "19 tensor(1.7254, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7380, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "20 tensor(1.7139, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7276, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "21 tensor(1.7023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7172, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "22 tensor(1.6903, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3190)\n",
      "The Current Loss: tensor(1.7062, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "23 tensor(1.6776, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3210)\n",
      "The Current Loss: tensor(1.6946, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "24 tensor(1.6640, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3230)\n",
      "The Current Loss: tensor(1.6822, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "25 tensor(1.6496, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3270)\n",
      "The Current Loss: tensor(1.6688, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "26 tensor(1.6342, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3360)\n",
      "The Current Loss: tensor(1.6545, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "27 tensor(1.6185, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3480)\n",
      "The Current Loss: tensor(1.6398, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "28 tensor(1.6027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3660)\n",
      "The Current Loss: tensor(1.6253, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "29 tensor(1.5867, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3820)\n",
      "The Current Loss: tensor(1.6106, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "30 tensor(1.5702, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4010)\n",
      "The Current Loss: tensor(1.5956, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "31 tensor(1.5533, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4220)\n",
      "The Current Loss: tensor(1.5803, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "32 tensor(1.5359, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4330)\n",
      "The Current Loss: tensor(1.5648, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "33 tensor(1.5180, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4500)\n",
      "The Current Loss: tensor(1.5490, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "34 tensor(1.4997, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4630)\n",
      "The Current Loss: tensor(1.5328, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "35 tensor(1.4810, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4770)\n",
      "The Current Loss: tensor(1.5163, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "36 tensor(1.4618, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4860)\n",
      "The Current Loss: tensor(1.4994, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "37 tensor(1.4422, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4980)\n",
      "The Current Loss: tensor(1.4822, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "38 tensor(1.4222, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5050)\n",
      "The Current Loss: tensor(1.4646, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "39 tensor(1.4018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5120)\n",
      "The Current Loss: tensor(1.4467, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "40 tensor(1.3812, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5200)\n",
      "The Current Loss: tensor(1.4286, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "41 tensor(1.3603, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5310)\n",
      "The Current Loss: tensor(1.4103, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "42 tensor(1.3392, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5400)\n",
      "The Current Loss: tensor(1.3917, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "43 tensor(1.3178, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5600)\n",
      "The Current Loss: tensor(1.3729, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "44 tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5800)\n",
      "The Current Loss: tensor(1.3540, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "45 tensor(1.2746, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5950)\n",
      "The Current Loss: tensor(1.3348, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "46 tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6110)\n",
      "The Current Loss: tensor(1.3156, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "47 tensor(1.2308, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6340)\n",
      "The Current Loss: tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "48 tensor(1.2089, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6550)\n",
      "The Current Loss: tensor(1.2771, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "49 tensor(1.1870, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6670)\n",
      "The Current Loss: tensor(1.2579, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "50 tensor(1.1651, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6790)\n",
      "The Current Loss: tensor(1.2388, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "51 tensor(1.1432, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6940)\n",
      "The Current Loss: tensor(1.2198, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "52 tensor(1.1212, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7130)\n",
      "The Current Loss: tensor(1.2008, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "53 tensor(1.0993, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7230)\n",
      "The Current Loss: tensor(1.1819, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "54 tensor(1.0772, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7310)\n",
      "The Current Loss: tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "55 tensor(1.0551, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7410)\n",
      "The Current Loss: tensor(1.1440, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "56 tensor(1.0328, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7500)\n",
      "The Current Loss: tensor(1.1248, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "57 tensor(1.0101, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7630)\n",
      "The Current Loss: tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "58 tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7680)\n",
      "The Current Loss: tensor(1.0854, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "59 tensor(0.9649, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7790)\n",
      "The Current Loss: tensor(1.0661, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "60 tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7910)\n",
      "The Current Loss: tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "61 tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7960)\n",
      "The Current Loss: tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "62 tensor(0.8998, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8030)\n",
      "The Current Loss: tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "63 tensor(0.8784, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8160)\n",
      "The Current Loss: tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 tensor(0.8573, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8210)\n",
      "The Current Loss: tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "65 tensor(0.8365, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8290)\n",
      "The Current Loss: tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "66 tensor(0.8160, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8310)\n",
      "The Current Loss: tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "67 tensor(0.7959, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8360)\n",
      "The Current Loss: tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "68 tensor(0.7761, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8410)\n",
      "The Current Loss: tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "69 tensor(0.7568, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8500)\n",
      "The Current Loss: tensor(0.8937, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "70 tensor(0.7378, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8520)\n",
      "The Current Loss: tensor(0.8786, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "71 tensor(0.7192, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8560)\n",
      "The Current Loss: tensor(0.8638, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "72 tensor(0.7011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8610)\n",
      "The Current Loss: tensor(0.8495, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "73 tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8690)\n",
      "The Current Loss: tensor(0.8356, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "74 tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8790)\n",
      "The Current Loss: tensor(0.8221, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "75 tensor(0.6493, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8810)\n",
      "The Current Loss: tensor(0.8090, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "76 tensor(0.6329, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8850)\n",
      "The Current Loss: tensor(0.7965, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "77 tensor(0.6170, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8910)\n",
      "The Current Loss: tensor(0.7843, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "78 tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8920)\n",
      "The Current Loss: tensor(0.7726, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "79 tensor(0.5865, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8950)\n",
      "The Current Loss: tensor(0.7614, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "80 tensor(0.5719, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8960)\n",
      "The Current Loss: tensor(0.7505, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "81 tensor(0.5578, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8990)\n",
      "The Current Loss: tensor(0.7401, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "82 tensor(0.5441, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9020)\n",
      "The Current Loss: tensor(0.7301, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "83 tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9050)\n",
      "The Current Loss: tensor(0.7205, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "84 tensor(0.5179, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9060)\n",
      "The Current Loss: tensor(0.7113, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "85 tensor(0.5055, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9090)\n",
      "The Current Loss: tensor(0.7025, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "86 tensor(0.4935, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9090)\n",
      "The Current Loss: tensor(0.6940, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "87 tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9130)\n",
      "The Current Loss: tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "88 tensor(0.4706, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9150)\n",
      "The Current Loss: tensor(0.6781, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "89 tensor(0.4597, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9160)\n",
      "The Current Loss: tensor(0.6707, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "90 tensor(0.4492, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9170)\n",
      "The Current Loss: tensor(0.6636, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "91 tensor(0.4391, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9210)\n",
      "The Current Loss: tensor(0.6568, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "92 tensor(0.4293, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9210)\n",
      "The Current Loss: tensor(0.6504, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "93 tensor(0.4198, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9230)\n",
      "The Current Loss: tensor(0.6442, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "94 tensor(0.4107, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9240)\n",
      "The Current Loss: tensor(0.6384, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "95 tensor(0.4019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9260)\n",
      "The Current Loss: tensor(0.6328, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "96 tensor(0.3934, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9260)\n",
      "The Current Loss: tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "97 tensor(0.3852, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9260)\n",
      "The Current Loss: tensor(0.6226, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "98 tensor(0.3773, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9270)\n",
      "The Current Loss: tensor(0.6178, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "99 tensor(0.3696, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9280)\n",
      "The Current Loss: tensor(0.6133, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "100 tensor(0.3623, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9320)\n",
      "The Current Loss: tensor(0.6090, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "101 tensor(0.3551, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9320)\n",
      "The Current Loss: tensor(0.6049, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "102 tensor(0.3482, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9330)\n",
      "The Current Loss: tensor(0.6010, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "103 tensor(0.3416, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9330)\n",
      "The Current Loss: tensor(0.5974, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "104 tensor(0.3352, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9330)\n",
      "The Current Loss: tensor(0.5939, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "105 tensor(0.3289, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9340)\n",
      "The Current Loss: tensor(0.5906, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "106 tensor(0.3229, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9350)\n",
      "The Current Loss: tensor(0.5875, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "107 tensor(0.3171, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9360)\n",
      "The Current Loss: tensor(0.5846, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "108 tensor(0.3115, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9400)\n",
      "The Current Loss: tensor(0.5819, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "109 tensor(0.3061, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9400)\n",
      "The Current Loss: tensor(0.5793, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "110 tensor(0.3008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9400)\n",
      "The Current Loss: tensor(0.5768, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "111 tensor(0.2957, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9430)\n",
      "The Current Loss: tensor(0.5745, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "112 tensor(0.2908, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9440)\n",
      "The Current Loss: tensor(0.5723, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "113 tensor(0.2860, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9460)\n",
      "The Current Loss: tensor(0.5703, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "114 tensor(0.2814, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9460)\n",
      "The Current Loss: tensor(0.5683, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "115 tensor(0.2769, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9480)\n",
      "The Current Loss: tensor(0.5665, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "116 tensor(0.2725, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9480)\n",
      "The Current Loss: tensor(0.5647, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "117 tensor(0.2683, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9490)\n",
      "The Current Loss: tensor(0.5631, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "118 tensor(0.2642, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9490)\n",
      "The Current Loss: tensor(0.5615, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "119 tensor(0.2603, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9510)\n",
      "The Current Loss: tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "120 tensor(0.2564, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9520)\n",
      "The Current Loss: tensor(0.5587, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "121 tensor(0.2526, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9520)\n",
      "The Current Loss: tensor(0.5575, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "122 tensor(0.2490, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9530)\n",
      "The Current Loss: tensor(0.5563, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "123 tensor(0.2455, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9530)\n",
      "The Current Loss: tensor(0.5552, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "124 tensor(0.2420, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9530)\n",
      "The Current Loss: tensor(0.5542, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "125 tensor(0.2387, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9530)\n",
      "The Current Loss: tensor(0.5532, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "126 tensor(0.2354, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.5523, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "127 tensor(0.2322, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.5515, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "128 tensor(0.2291, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.5508, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "129 tensor(0.2261, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.5501, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "130 tensor(0.2232, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.5495, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "131 tensor(0.2203, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.5489, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "132 tensor(0.2176, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.5484, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "133 tensor(0.2148, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9550)\n",
      "The Current Loss: tensor(0.5479, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "134 tensor(0.2122, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9550)\n",
      "The Current Loss: tensor(0.5475, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "135 tensor(0.2096, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9570)\n",
      "The Current Loss: tensor(0.5471, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "136 tensor(0.2071, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9590)\n",
      "The Current Loss: tensor(0.5468, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "137 tensor(0.2046, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9590)\n",
      "The Current Loss: tensor(0.5464, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "138 tensor(0.2022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9590)\n",
      "The Current Loss: tensor(0.5462, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "139 tensor(0.1998, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9600)\n",
      "The Current Loss: tensor(0.5459, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "140 tensor(0.1975, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9600)\n",
      "The Current Loss: tensor(0.5457, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "141 tensor(0.1953, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9610)\n",
      "The Current Loss: tensor(0.5455, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "142 tensor(0.1930, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9630)\n",
      "The Current Loss: tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "143 tensor(0.1909, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9640)\n",
      "The Current Loss: tensor(0.5453, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "144 tensor(0.1888, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9640)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "145 tensor(0.1867, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9650)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "146 tensor(0.1847, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9650)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "147 tensor(0.1827, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9660)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "148 tensor(0.1807, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9670)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "149 tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9680)\n",
      "The Current Loss: tensor(0.5453, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "150 tensor(0.1769, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9690)\n",
      "The Current Loss: tensor(0.5453, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "151 tensor(0.1751, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9710)\n",
      "The Current Loss: tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "152 tensor(0.1733, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9710)\n",
      "The Current Loss: tensor(0.5455, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "153 tensor(0.1715, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9710)\n",
      "The Current Loss: tensor(0.5456, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "154 tensor(0.1698, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5458, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "155 tensor(0.1681, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5459, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "156 tensor(0.1664, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5461, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "157 tensor(0.1648, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5463, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "158 tensor(0.1632, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5465, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "159 tensor(0.1616, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5467, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "160 tensor(0.1600, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9720)\n",
      "The Current Loss: tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "161 tensor(0.1585, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9730)\n",
      "The Current Loss: tensor(0.5472, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "162 tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9730)\n",
      "The Current Loss: tensor(0.5475, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "163 tensor(0.1555, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9740)\n",
      "The Current Loss: tensor(0.5478, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "164 tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9740)\n",
      "The Current Loss: tensor(0.5480, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "165 tensor(0.1526, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9750)\n",
      "The Current Loss: tensor(0.5483, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "166 tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9750)\n",
      "The Current Loss: tensor(0.5487, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "167 tensor(0.1498, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9750)\n",
      "The Current Loss: tensor(0.5490, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "168 tensor(0.1485, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9750)\n",
      "The Current Loss: tensor(0.5493, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "169 tensor(0.1471, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9750)\n",
      "The Current Loss: tensor(0.5496, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "170 tensor(0.1458, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9770)\n",
      "The Current Loss: tensor(0.5500, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "171 tensor(0.1445, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9770)\n",
      "The Current Loss: tensor(0.5503, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "172 tensor(0.1432, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5507, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "173 tensor(0.1420, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5511, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "174 tensor(0.1407, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5515, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "175 tensor(0.1395, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5518, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "176 tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5522, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "177 tensor(0.1371, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5526, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "178 tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5530, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "179 tensor(0.1348, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5534, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "180 tensor(0.1337, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "181 tensor(0.1325, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5543, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "182 tensor(0.1314, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5547, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "183 tensor(0.1303, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9780)\n",
      "The Current Loss: tensor(0.5551, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "184 tensor(0.1293, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9790)\n",
      "The Current Loss: tensor(0.5556, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "185 tensor(0.1282, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9800)\n",
      "The Current Loss: tensor(0.5560, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "186 tensor(0.1272, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9800)\n",
      "The Current Loss: tensor(0.5565, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "187 tensor(0.1261, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9810)\n",
      "The Current Loss: tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "188 tensor(0.1251, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9810)\n",
      "The Current Loss: tensor(0.5574, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "189 tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9810)\n",
      "The Current Loss: tensor(0.5578, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 tensor(0.1231, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9810)\n",
      "The Current Loss: tensor(0.5583, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "191 tensor(0.1221, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9820)\n",
      "The Current Loss: tensor(0.5588, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "192 tensor(0.1212, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9820)\n",
      "The Current Loss: tensor(0.5593, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "193 tensor(0.1202, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9820)\n",
      "The Current Loss: tensor(0.5597, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "194 tensor(0.1193, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9830)\n",
      "The Current Loss: tensor(0.5602, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "195 tensor(0.1183, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5607, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "196 tensor(0.1174, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5612, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "197 tensor(0.1165, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5617, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "198 tensor(0.1156, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5622, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "199 tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5627, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "200 tensor(0.1138, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5632, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "201 tensor(0.1130, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5637, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "202 tensor(0.1121, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5642, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "203 tensor(0.1113, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5648, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "204 tensor(0.1104, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5653, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "205 tensor(0.1096, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5658, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "206 tensor(0.1088, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5664, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "207 tensor(0.1080, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9840)\n",
      "The Current Loss: tensor(0.5669, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "208 tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5674, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "209 tensor(0.1064, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5680, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "210 tensor(0.1056, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5685, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "211 tensor(0.1048, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5690, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "212 tensor(0.1041, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5696, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "213 tensor(0.1033, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5701, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "214 tensor(0.1026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5707, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "215 tensor(0.1018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5712, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "216 tensor(0.1011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5718, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "217 tensor(0.1004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5723, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "218 tensor(0.0997, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5729, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "219 tensor(0.0990, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5735, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "220 tensor(0.0983, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5741, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "221 tensor(0.0976, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5746, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "222 tensor(0.0969, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5752, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "223 tensor(0.0962, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5758, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "224 tensor(0.0955, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5763, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "225 tensor(0.0949, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5769, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "226 tensor(0.0942, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5775, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "227 tensor(0.0936, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5781, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "228 tensor(0.0929, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5786, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "229 tensor(0.0923, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5792, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "230 tensor(0.0917, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5798, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "231 tensor(0.0910, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5804, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "232 tensor(0.0904, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5810, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "233 tensor(0.0898, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5816, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "234 tensor(0.0892, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5822, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "235 tensor(0.0886, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "236 tensor(0.0880, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5834, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "237 tensor(0.0874, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5840, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "238 tensor(0.0868, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5846, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "239 tensor(0.0863, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5852, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "240 tensor(0.0857, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5858, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "241 tensor(0.0851, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9850)\n",
      "The Current Loss: tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "242 tensor(0.0846, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "243 tensor(0.0840, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5876, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "244 tensor(0.0835, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5882, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "245 tensor(0.0829, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5888, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "246 tensor(0.0824, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5895, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "247 tensor(0.0819, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5901, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "248 tensor(0.0813, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5907, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "249 tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.5913, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 tensor(0.0803, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.5919, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "251 tensor(0.0798, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "252 tensor(0.0793, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "253 tensor(0.0788, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.5938, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "254 tensor(0.0783, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5944, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "255 tensor(0.0778, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5950, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "256 tensor(0.0773, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5957, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "257 tensor(0.0768, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5963, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "258 tensor(0.0763, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5969, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "259 tensor(0.0759, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5975, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "260 tensor(0.0754, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5982, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "261 tensor(0.0749, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5988, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "262 tensor(0.0745, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.5994, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "263 tensor(0.0740, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.6001, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "264 tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.6007, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "265 tensor(0.0731, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.6013, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "266 tensor(0.0726, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9890)\n",
      "The Current Loss: tensor(0.6020, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "267 tensor(0.0722, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6026, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "268 tensor(0.0718, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6033, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "269 tensor(0.0713, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6039, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "270 tensor(0.0709, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6045, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "271 tensor(0.0705, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6052, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "272 tensor(0.0701, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6058, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "273 tensor(0.0696, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6065, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "274 tensor(0.0692, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6072, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "275 tensor(0.0688, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6078, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "276 tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6085, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "277 tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "278 tensor(0.0676, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6098, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "279 tensor(0.0672, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6105, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "280 tensor(0.0668, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6111, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "281 tensor(0.0664, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6118, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "282 tensor(0.0660, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6125, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "283 tensor(0.0656, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6131, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "284 tensor(0.0653, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6138, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "285 tensor(0.0649, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6144, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "286 tensor(0.0645, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6151, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "287 tensor(0.0641, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6158, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "288 tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6165, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "289 tensor(0.0634, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6171, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "290 tensor(0.0631, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6178, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "291 tensor(0.0627, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6184, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "292 tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6191, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "293 tensor(0.0620, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6198, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "294 tensor(0.0616, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6205, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "295 tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.6211, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "296 tensor(0.0610, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6218, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "297 tensor(0.0606, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6225, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "298 tensor(0.0603, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6232, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "299 tensor(0.0599, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6238, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "300 tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6245, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "301 tensor(0.0593, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6252, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "302 tensor(0.0590, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6259, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "303 tensor(0.0586, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6266, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "304 tensor(0.0583, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6273, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "305 tensor(0.0580, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6279, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "306 tensor(0.0577, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9920)\n",
      "The Current Loss: tensor(0.6286, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "307 tensor(0.0574, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9930)\n",
      "The Current Loss: tensor(0.6293, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "308 tensor(0.0571, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.6300, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "309 tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.6307, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.6314, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "311 tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.6321, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "312 tensor(0.0558, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.6327, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "313 tensor(0.0555, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6334, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "314 tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "315 tensor(0.0549, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6348, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "316 tensor(0.0547, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6355, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "317 tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6362, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "318 tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6369, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "319 tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6376, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "320 tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6383, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "321 tensor(0.0532, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6390, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "322 tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6397, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "323 tensor(0.0527, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6404, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "324 tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6411, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "325 tensor(0.0521, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6418, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "326 tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6425, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "327 tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6432, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "328 tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6439, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "329 tensor(0.0511, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6446, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "330 tensor(0.0508, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6454, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "331 tensor(0.0506, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6461, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "332 tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6468, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "333 tensor(0.0501, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6475, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "334 tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6482, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "335 tensor(0.0495, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6489, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "336 tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6496, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "337 tensor(0.0491, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6503, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "338 tensor(0.0488, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6510, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "339 tensor(0.0486, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6518, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "340 tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6525, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "341 tensor(0.0481, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6532, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "342 tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6539, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "343 tensor(0.0476, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6546, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "344 tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6554, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "345 tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6561, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "346 tensor(0.0469, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6568, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "347 tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6575, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "348 tensor(0.0465, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6583, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "349 tensor(0.0462, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6590, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "350 tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6597, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "351 tensor(0.0458, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6604, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "352 tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6611, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "353 tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6618, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "354 tensor(0.0451, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6625, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "355 tensor(0.0449, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6633, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "356 tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6640, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "357 tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6647, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "358 tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6654, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "359 tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "360 tensor(0.0439, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6669, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "361 tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6676, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "362 tensor(0.0435, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6683, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "363 tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6691, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "364 tensor(0.0431, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6698, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "365 tensor(0.0429, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "366 tensor(0.0427, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6713, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "367 tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6720, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "368 tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "369 tensor(0.0421, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6735, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "370 tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6742, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "371 tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6749, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "372 tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6757, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "373 tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.6764, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "374 tensor(0.0411, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "375 tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6778, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "376 tensor(0.0408, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6786, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "377 tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6793, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "378 tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6800, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "379 tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6808, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "380 tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6815, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "381 tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6822, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "382 tensor(0.0397, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6829, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "383 tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6837, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "384 tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6844, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "385 tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6852, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "386 tensor(0.0390, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "387 tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6866, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "388 tensor(0.0386, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6873, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "389 tensor(0.0385, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6881, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "390 tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6888, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "391 tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6895, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "392 tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6903, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "393 tensor(0.0378, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6910, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "394 tensor(0.0377, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "395 tensor(0.0375, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "396 tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6932, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "397 tensor(0.0372, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6939, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "398 tensor(0.0370, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6947, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "399 tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6954, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "400 tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6961, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "401 tensor(0.0365, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6969, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "402 tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6976, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "403 tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6983, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "404 tensor(0.0361, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6991, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "405 tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.6998, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "406 tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7005, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "407 tensor(0.0356, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7013, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "408 tensor(0.0355, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7020, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "409 tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7027, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "410 tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7034, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "411 tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7042, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "412 tensor(0.0349, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7049, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "413 tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7056, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "414 tensor(0.0346, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7063, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "415 tensor(0.0345, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7071, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "416 tensor(0.0343, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7078, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "417 tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7085, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "418 tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7092, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "419 tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7100, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "420 tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7107, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "421 tensor(0.0337, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7114, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "422 tensor(0.0335, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7121, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "423 tensor(0.0334, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7129, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "424 tensor(0.0333, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7136, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "425 tensor(0.0331, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7143, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "426 tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7150, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "427 tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7158, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "428 tensor(0.0327, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7165, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "429 tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7172, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "430 tensor(0.0325, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7180, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "431 tensor(0.0323, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7187, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "432 tensor(0.0322, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7194, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "433 tensor(0.0321, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7201, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "434 tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7208, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "435 tensor(0.0318, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7216, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "436 tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7223, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "437 tensor(0.0316, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.7230, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "438 tensor(0.0315, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7237, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "439 tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7244, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "440 tensor(0.0312, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7252, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "441 tensor(0.0311, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7259, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "442 tensor(0.0310, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7266, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "443 tensor(0.0309, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7273, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "444 tensor(0.0308, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7280, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "445 tensor(0.0306, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7288, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "446 tensor(0.0305, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7295, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "447 tensor(0.0304, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7302, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "448 tensor(0.0303, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7309, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "449 tensor(0.0302, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7316, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "450 tensor(0.0301, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7324, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "451 tensor(0.0300, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7331, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "452 tensor(0.0298, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7338, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "453 tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7345, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "454 tensor(0.0296, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7352, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "455 tensor(0.0295, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7359, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "456 tensor(0.0294, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7366, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "457 tensor(0.0293, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7373, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "458 tensor(0.0292, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7381, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "459 tensor(0.0291, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7388, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "460 tensor(0.0290, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7395, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "461 tensor(0.0289, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7402, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "462 tensor(0.0288, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7409, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "463 tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7416, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "464 tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7423, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "465 tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7430, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "466 tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7438, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "467 tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7445, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "468 tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7452, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "469 tensor(0.0281, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7459, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "470 tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7466, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "471 tensor(0.0279, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7473, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "472 tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7480, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "473 tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7487, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "474 tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7494, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "475 tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7501, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "476 tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7509, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "477 tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7516, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "478 tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7522, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "479 tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7530, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "480 tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7537, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "481 tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7544, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "482 tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7551, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "483 tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7558, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "484 tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7565, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "485 tensor(0.0265, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7572, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "486 tensor(0.0264, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7579, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "487 tensor(0.0263, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7586, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "488 tensor(0.0263, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7593, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "489 tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7600, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "490 tensor(0.0261, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7607, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "491 tensor(0.0260, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7614, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "492 tensor(0.0259, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7621, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "493 tensor(0.0258, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.7628, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7635, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "495 tensor(0.0256, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7642, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "496 tensor(0.0255, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7649, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "497 tensor(0.0255, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7656, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "498 tensor(0.0254, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7663, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "499 tensor(0.0253, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7670, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "500 tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7676, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "501 tensor(0.0251, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7683, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "502 tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7690, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "503 tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7697, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "504 tensor(0.0249, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7704, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "505 tensor(0.0248, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7711, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "506 tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7718, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "507 tensor(0.0246, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7725, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "508 tensor(0.0246, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7732, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "509 tensor(0.0245, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7739, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "510 tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7746, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "511 tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7753, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "512 tensor(0.0242, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7759, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "513 tensor(0.0242, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7766, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "514 tensor(0.0241, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7773, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "515 tensor(0.0240, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7780, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "516 tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7787, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "517 tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7794, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "518 tensor(0.0238, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7801, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "519 tensor(0.0237, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7808, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "520 tensor(0.0236, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7814, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "521 tensor(0.0236, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7821, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "522 tensor(0.0235, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7828, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "523 tensor(0.0234, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7835, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "524 tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7842, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "525 tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7849, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "526 tensor(0.0232, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7856, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "527 tensor(0.0231, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7862, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "528 tensor(0.0230, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7869, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "529 tensor(0.0230, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7876, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "530 tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7883, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "531 tensor(0.0228, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7890, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "532 tensor(0.0228, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7896, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "533 tensor(0.0227, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7903, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "534 tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7910, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "535 tensor(0.0225, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7917, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "536 tensor(0.0225, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7923, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "537 tensor(0.0224, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7930, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "538 tensor(0.0223, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7937, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "539 tensor(0.0223, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7944, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "540 tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7950, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "541 tensor(0.0221, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7957, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "542 tensor(0.0221, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7964, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "543 tensor(0.0220, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7971, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "544 tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7977, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "545 tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7984, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "546 tensor(0.0218, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7991, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "547 tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.7997, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "548 tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8004, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "549 tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8011, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "550 tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8018, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "551 tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8024, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "552 tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8031, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "553 tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8038, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 tensor(0.0213, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8044, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "555 tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8051, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "556 tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8058, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "557 tensor(0.0211, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8064, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "558 tensor(0.0211, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8071, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "559 tensor(0.0210, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8078, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "560 tensor(0.0209, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8084, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "561 tensor(0.0209, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8091, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "562 tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8098, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "563 tensor(0.0207, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8104, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "564 tensor(0.0207, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8111, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "565 tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8118, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "566 tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8124, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "567 tensor(0.0205, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8131, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "568 tensor(0.0205, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8137, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "569 tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8144, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "570 tensor(0.0203, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8151, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "571 tensor(0.0203, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8157, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "572 tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8164, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "573 tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8170, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "574 tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8177, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "575 tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8184, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "576 tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8190, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "577 tensor(0.0199, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8197, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "578 tensor(0.0199, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8203, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "579 tensor(0.0198, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8210, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "580 tensor(0.0198, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8216, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "581 tensor(0.0197, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8223, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "582 tensor(0.0197, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8230, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "583 tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8236, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "584 tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8243, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "585 tensor(0.0195, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8249, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "586 tensor(0.0195, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8256, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "587 tensor(0.0194, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8262, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "588 tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8269, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "589 tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8275, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "590 tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8282, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "591 tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8288, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "592 tensor(0.0191, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8295, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "593 tensor(0.0191, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8301, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "594 tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8308, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "595 tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8314, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "596 tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8321, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "597 tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8327, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "598 tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8334, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "599 tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8340, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "600 tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8347, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "601 tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8353, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "602 tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8359, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "603 tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8366, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "604 tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.8372, grad_fn=<NllLossBackward0>)\n",
      "0\n",
      "trigger times: 0\n",
      "605 tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17956\\262405245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m                             )\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 state_steps)\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             adam(\n\u001b[0m\u001b[0;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m     func(params,\n\u001b[0m\u001b[0;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 1000\n",
    "patience=5\n",
    "trigger_times=0\n",
    "last_loss=0\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(G, features)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(logits[train_mask], G.ndata['label'][train_mask])\n",
    "#     last_loss=loss\n",
    "    print(epoch, loss)\n",
    "    print('acc', (logits[train_mask].argmax(dim=1) == G.ndata['label'][train_mask]).float().mean())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    current_loss = validation(model,  nn.CrossEntropyLoss())\n",
    "    print('The Current Loss:', current_loss)\n",
    "    print(trigger_times )\n",
    "\n",
    "    if (current_loss - last_loss) > 0.1:\n",
    "            trigger_times += 1\n",
    "            last_loss=current_loss\n",
    "            if trigger_times >= patience:\n",
    "                print(trigger_times )\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "\n",
    "    else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "            last_loss=current_loss\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(G, features)\n",
    "    loss_test = nn.CrossEntropyLoss()(pred[test_mask], G.ndata['label'][test_mask])\n",
    "accuracy = (pred[test_mask].argmax(dim=1) == G.ndata['label'][test_mask]).float().mean()\n",
    "print(f\"Accuracy on test set: {accuracy.item()}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53c08f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9869, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1480)\n",
      "The Current Loss: tensor(1.9841, grad_fn=<NllLossBackward0>)\n",
      "1 tensor(1.9451, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1720)\n",
      "The Current Loss: tensor(1.9488, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "2 tensor(1.9044, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.2450)\n",
      "The Current Loss: tensor(1.9147, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "3 tensor(1.8593, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5000)\n",
      "The Current Loss: tensor(1.8774, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "4 tensor(1.8108, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4160)\n",
      "The Current Loss: tensor(1.8378, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "5 tensor(1.7598, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4060)\n",
      "The Current Loss: tensor(1.7965, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "6 tensor(1.7079, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4130)\n",
      "The Current Loss: tensor(1.7541, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "7 tensor(1.6576, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4160)\n",
      "The Current Loss: tensor(1.7131, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "8 tensor(1.6091, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4170)\n",
      "The Current Loss: tensor(1.6741, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "9 tensor(1.5611, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4160)\n",
      "The Current Loss: tensor(1.6358, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "10 tensor(1.5132, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4170)\n",
      "The Current Loss: tensor(1.5977, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "11 tensor(1.4655, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4240)\n",
      "The Current Loss: tensor(1.5599, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "12 tensor(1.4179, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4330)\n",
      "The Current Loss: tensor(1.5223, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "13 tensor(1.3698, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4590)\n",
      "The Current Loss: tensor(1.4841, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "14 tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4930)\n",
      "The Current Loss: tensor(1.4445, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "15 tensor(1.2690, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5320)\n",
      "The Current Loss: tensor(1.4031, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "16 tensor(1.2163, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5820)\n",
      "The Current Loss: tensor(1.3601, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "17 tensor(1.1636, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6360)\n",
      "The Current Loss: tensor(1.3171, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "18 tensor(1.1125, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6690)\n",
      "The Current Loss: tensor(1.2755, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "19 tensor(1.0627, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7110)\n",
      "The Current Loss: tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "20 tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7470)\n",
      "The Current Loss: tensor(1.1951, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "21 tensor(0.9648, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7780)\n",
      "The Current Loss: tensor(1.1551, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "22 tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7940)\n",
      "The Current Loss: tensor(1.1152, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "23 tensor(0.8694, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8180)\n",
      "The Current Loss: tensor(1.0755, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "24 tensor(0.8236, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8320)\n",
      "The Current Loss: tensor(1.0365, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "25 tensor(0.7794, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8520)\n",
      "The Current Loss: tensor(0.9987, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "26 tensor(0.7371, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8720)\n",
      "The Current Loss: tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "27 tensor(0.6969, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8870)\n",
      "The Current Loss: tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "28 tensor(0.6585, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8950)\n",
      "The Current Loss: tensor(0.8948, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "29 tensor(0.6219, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9020)\n",
      "The Current Loss: tensor(0.8637, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "30 tensor(0.5871, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9090)\n",
      "The Current Loss: tensor(0.8342, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "31 tensor(0.5541, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9150)\n",
      "The Current Loss: tensor(0.8063, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "32 tensor(0.5227, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9200)\n",
      "The Current Loss: tensor(0.7801, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "33 tensor(0.4930, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9270)\n",
      "The Current Loss: tensor(0.7555, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "34 tensor(0.4649, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9280)\n",
      "The Current Loss: tensor(0.7323, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "35 tensor(0.4383, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9320)\n",
      "The Current Loss: tensor(0.7104, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "36 tensor(0.4132, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9370)\n",
      "The Current Loss: tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "37 tensor(0.3897, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9450)\n",
      "The Current Loss: tensor(0.6709, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "38 tensor(0.3676, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9460)\n",
      "The Current Loss: tensor(0.6531, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "39 tensor(0.3470, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9500)\n",
      "The Current Loss: tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "40 tensor(0.3276, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9540)\n",
      "The Current Loss: tensor(0.6212, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "41 tensor(0.3095, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9600)\n",
      "The Current Loss: tensor(0.6070, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "42 tensor(0.2925, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9610)\n",
      "The Current Loss: tensor(0.5937, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "43 tensor(0.2766, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9650)\n",
      "The Current Loss: tensor(0.5814, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "44 tensor(0.2617, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9680)\n",
      "The Current Loss: tensor(0.5698, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "45 tensor(0.2477, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9700)\n",
      "The Current Loss: tensor(0.5591, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "46 tensor(0.2346, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9700)\n",
      "The Current Loss: tensor(0.5491, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "47 tensor(0.2223, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9730)\n",
      "The Current Loss: tensor(0.5398, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "48 tensor(0.2107, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9740)\n",
      "The Current Loss: tensor(0.5313, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "49 tensor(0.1999, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9760)\n",
      "The Current Loss: tensor(0.5235, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "50 tensor(0.1896, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9770)\n",
      "The Current Loss: tensor(0.5164, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "51 tensor(0.1801, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9790)\n",
      "The Current Loss: tensor(0.5100, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "52 tensor(0.1710, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9810)\n",
      "The Current Loss: tensor(0.5042, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "53 tensor(0.1626, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9820)\n",
      "The Current Loss: tensor(0.4990, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "54 tensor(0.1546, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9830)\n",
      "The Current Loss: tensor(0.4944, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "55 tensor(0.1470, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9860)\n",
      "The Current Loss: tensor(0.4902, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "56 tensor(0.1399, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9860)\n",
      "The Current Loss: tensor(0.4865, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "57 tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9870)\n",
      "The Current Loss: tensor(0.4831, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "58 tensor(0.1268, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.4801, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "59 tensor(0.1208, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.4774, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "60 tensor(0.1151, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.4750, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "61 tensor(0.1098, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9880)\n",
      "The Current Loss: tensor(0.4729, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "62 tensor(0.1047, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9900)\n",
      "The Current Loss: tensor(0.4711, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "63 tensor(0.1000, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9910)\n",
      "The Current Loss: tensor(0.4694, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "64 tensor(0.0955, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9930)\n",
      "The Current Loss: tensor(0.4680, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "65 tensor(0.0912, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9930)\n",
      "The Current Loss: tensor(0.4668, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "66 tensor(0.0872, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.4658, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 tensor(0.0834, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.4650, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "68 tensor(0.0799, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.4644, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "69 tensor(0.0765, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9940)\n",
      "The Current Loss: tensor(0.4639, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "70 tensor(0.0734, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9950)\n",
      "The Current Loss: tensor(0.4635, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "71 tensor(0.0704, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.4632, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "72 tensor(0.0676, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9960)\n",
      "The Current Loss: tensor(0.4631, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "73 tensor(0.0650, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9970)\n",
      "The Current Loss: tensor(0.4630, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "74 tensor(0.0625, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9980)\n",
      "The Current Loss: tensor(0.4630, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "75 tensor(0.0601, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9990)\n",
      "The Current Loss: tensor(0.4631, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "76 tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9990)\n",
      "The Current Loss: tensor(0.4633, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "77 tensor(0.0558, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9990)\n",
      "The Current Loss: tensor(0.4635, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "78 tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9990)\n",
      "The Current Loss: tensor(0.4638, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "79 tensor(0.0519, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9990)\n",
      "The Current Loss: tensor(0.4641, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "80 tensor(0.0500, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.9990)\n",
      "The Current Loss: tensor(0.4645, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "81 tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4649, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "82 tensor(0.0467, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4653, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "83 tensor(0.0452, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4658, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "84 tensor(0.0437, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4663, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "85 tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4668, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "86 tensor(0.0410, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4674, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "87 tensor(0.0397, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4679, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "88 tensor(0.0385, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4685, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "89 tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4690, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "90 tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4696, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "91 tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4701, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "92 tensor(0.0342, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4707, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "93 tensor(0.0332, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4713, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "94 tensor(0.0323, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4718, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "95 tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4724, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "96 tensor(0.0306, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4730, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "97 tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4736, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "98 tensor(0.0290, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4742, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "99 tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4748, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "100 tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4754, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "101 tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4760, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "102 tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4766, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "103 tensor(0.0256, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4773, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "104 tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4779, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "105 tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4785, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "106 tensor(0.0238, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4791, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "107 tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "108 tensor(0.0228, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4803, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "109 tensor(0.0223, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4809, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "110 tensor(0.0218, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4816, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "111 tensor(0.0213, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4822, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "112 tensor(0.0209, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4828, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "113 tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4834, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "114 tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4840, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "115 tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4846, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "116 tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4852, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "117 tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4857, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "118 tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4863, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "119 tensor(0.0181, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4869, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "120 tensor(0.0178, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4875, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "121 tensor(0.0174, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4881, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "122 tensor(0.0171, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4887, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "123 tensor(0.0168, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4893, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "124 tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4899, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "125 tensor(0.0162, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4905, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "126 tensor(0.0159, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4910, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "127 tensor(0.0156, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4916, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "128 tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4922, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "129 tensor(0.0151, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4928, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "130 tensor(0.0149, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4934, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "131 tensor(0.0146, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4940, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "132 tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4945, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "133 tensor(0.0141, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4951, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "134 tensor(0.0139, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.4957, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "135 tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4962, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "136 tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4968, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "137 tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4973, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "138 tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4979, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "139 tensor(0.0128, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4984, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "140 tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4990, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "141 tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.4995, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "142 tensor(0.0123, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5000, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "143 tensor(0.0121, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5006, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "144 tensor(0.0119, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5011, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "145 tensor(0.0117, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5016, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "146 tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5022, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "147 tensor(0.0114, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5027, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "148 tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5033, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "149 tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5038, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "150 tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5043, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "151 tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5049, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "152 tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5054, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "153 tensor(0.0105, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5059, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "154 tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5065, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "155 tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5070, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "156 tensor(0.0101, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5075, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "157 tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5080, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "158 tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5086, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "159 tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5091, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "160 tensor(0.0096, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5096, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "161 tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5101, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "162 tensor(0.0093, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5106, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "163 tensor(0.0092, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5111, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "164 tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5116, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "165 tensor(0.0090, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5121, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "166 tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5126, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "167 tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5131, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "168 tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5136, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "169 tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5141, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "170 tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5146, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "171 tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5151, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "172 tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5156, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "173 tensor(0.0081, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5160, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "174 tensor(0.0081, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5165, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "175 tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5170, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "176 tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5175, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "177 tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5179, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "178 tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5184, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "179 tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5189, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "180 tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5193, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "181 tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5198, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "182 tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5203, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "183 tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5207, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "184 tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5212, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "185 tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5217, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "186 tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5221, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "187 tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5226, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "188 tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5230, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "189 tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5235, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "190 tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5240, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "191 tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5244, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "192 tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5249, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "193 tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5253, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "194 tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5257, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "195 tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.5262, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "196 tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5266, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "197 tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5271, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "198 tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5275, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "199 tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5279, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "200 tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5284, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "201 tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5288, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "202 tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5292, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "203 tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5296, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "204 tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5301, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "205 tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5305, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "206 tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5309, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "207 tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5313, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "208 tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5318, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "209 tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5322, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "210 tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5326, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "211 tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5330, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "212 tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5334, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "213 tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5338, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "214 tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5342, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "215 tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5347, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "216 tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5351, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "217 tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5355, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "218 tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5359, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "219 tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5363, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "220 tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5367, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "221 tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5371, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "222 tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5375, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "223 tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5379, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "224 tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5383, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "225 tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5387, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "226 tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5391, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "227 tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5395, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "228 tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5398, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "229 tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5402, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "230 tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5406, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "231 tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5410, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "232 tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5414, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "233 tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5418, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "234 tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5422, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "235 tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5425, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "236 tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5429, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "237 tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5433, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "238 tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5437, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "239 tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5441, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "240 tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5444, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "241 tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5448, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "242 tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "243 tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5456, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "244 tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5459, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "245 tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5463, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "246 tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5467, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "247 tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "248 tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5474, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "249 tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5478, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "250 tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5481, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "251 tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5485, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "252 tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5488, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "253 tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5492, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "254 tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.5496, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "255 tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5499, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "256 tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5503, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "257 tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5506, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "258 tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5510, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "259 tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5513, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "260 tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5517, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "261 tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5520, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "262 tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5524, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "263 tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5527, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "264 tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5531, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "265 tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5534, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "266 tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "267 tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5541, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "268 tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5545, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "269 tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5548, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "270 tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5551, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "271 tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5555, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "272 tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5558, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "273 tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5562, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "274 tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5565, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "275 tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5568, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "276 tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5572, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "277 tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5575, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "278 tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5578, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "279 tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5582, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "280 tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5585, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "281 tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5588, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "282 tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5592, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "283 tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5595, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "284 tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5598, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "285 tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "286 tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5605, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "287 tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5608, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "288 tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5611, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "289 tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5614, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "290 tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5618, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "291 tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5621, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "292 tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5624, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "293 tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5627, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "294 tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5630, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "295 tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5634, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "296 tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5637, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "297 tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5640, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "298 tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5643, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "299 tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5646, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "300 tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5649, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "301 tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5652, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "302 tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5655, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "303 tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5659, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "304 tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5662, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "305 tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5665, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "306 tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5668, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "307 tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5671, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "308 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5674, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "309 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5677, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "310 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5680, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "311 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5683, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "312 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5686, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "313 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.5689, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "314 tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5692, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "315 tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5695, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "316 tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5698, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "317 tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5701, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "318 tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "319 tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5707, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "320 tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5710, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "321 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5713, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "322 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5716, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "323 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5719, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "324 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5722, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "325 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5725, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "326 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5728, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "327 tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5731, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "328 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5733, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "329 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5736, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "330 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5739, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "331 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5742, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "332 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5745, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "333 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5748, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "334 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5751, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "335 tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5754, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "336 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5756, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "337 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5759, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "338 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5762, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "339 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5765, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "340 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5768, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "341 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5771, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "342 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5773, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "343 tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5776, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "344 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5779, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "345 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5782, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "346 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5784, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "347 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5787, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "348 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5790, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "349 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5793, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "350 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5796, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "351 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5798, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "352 tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5801, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "353 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5804, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "354 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5806, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "355 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5809, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "356 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5812, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "357 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5815, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "358 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5817, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "359 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5820, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "360 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5823, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "361 tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5825, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "362 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "363 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5831, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "364 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5833, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "365 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5836, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "366 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5839, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "367 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5841, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "368 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5844, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "369 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5847, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "370 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5849, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "371 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5852, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "372 tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5854, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "373 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5857, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "374 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5860, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "375 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.5862, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "376 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5865, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "377 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5867, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "378 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "379 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5872, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "380 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5875, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "381 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5878, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "382 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5880, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "383 tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5883, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "384 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5885, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "385 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5888, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "386 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5890, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "387 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5893, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "388 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5895, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "389 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5898, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "390 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5900, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "391 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5903, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "392 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5905, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "393 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5908, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "394 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5910, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "395 tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5913, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "396 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5915, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "397 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5917, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "398 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5920, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "399 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5922, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "400 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "401 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5927, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "402 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5930, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "403 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "404 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5934, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "405 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5937, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "406 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5939, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "407 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5942, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "408 tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5944, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "409 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5947, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "410 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5949, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "411 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5951, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "412 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5954, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "413 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5956, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "414 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5959, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "415 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5961, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "416 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5963, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "417 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5966, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "418 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5968, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "419 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5970, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "420 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5973, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "421 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5975, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "422 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5977, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "423 tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5980, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "424 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5982, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "425 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5984, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "426 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5987, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "427 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5989, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "428 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5991, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "429 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5994, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "430 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5996, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "431 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.5998, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "432 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6000, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "433 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6003, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "434 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6005, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "435 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6007, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "436 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6009, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "437 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6012, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "438 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6014, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "439 tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "440 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6019, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "441 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6021, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "442 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6023, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6025, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "444 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6028, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "445 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6030, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "446 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6032, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "447 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6034, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "448 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6036, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "449 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6039, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "450 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6041, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "451 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6043, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "452 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6045, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "453 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6047, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "454 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6050, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "455 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6052, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "456 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6054, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "457 tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6056, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "458 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6058, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "459 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6061, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "460 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6063, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "461 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6065, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "462 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6067, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "463 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6069, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "464 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6071, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "465 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6073, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "466 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6076, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "467 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6078, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "468 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6080, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "469 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6082, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "470 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6084, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "471 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6086, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "472 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6088, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "473 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6090, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "474 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6093, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "475 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6095, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "476 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6097, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "477 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6099, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "478 tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6101, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "479 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6103, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "480 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6105, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "481 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6107, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "482 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6109, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "483 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6111, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "484 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6113, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "485 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6116, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "486 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6118, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "487 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6120, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "488 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6122, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "489 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6124, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "490 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6126, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "491 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6128, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "492 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6130, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "493 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6132, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "494 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6134, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "495 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6136, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "496 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6138, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "497 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6140, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "498 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6142, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "499 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6144, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "500 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6146, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "501 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6148, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "502 tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6150, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "503 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6152, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "504 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6154, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "505 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6156, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "506 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6158, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "507 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6160, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "508 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6162, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "509 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6164, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "510 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6166, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6168, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "512 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6170, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "513 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6172, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "514 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6174, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "515 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6176, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "516 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6178, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "517 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6180, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "518 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6182, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "519 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6184, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "520 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6186, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "521 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6188, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "522 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6190, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "523 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6192, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "524 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6193, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "525 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6195, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "526 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6197, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "527 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6199, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "528 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6201, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "529 tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6203, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "530 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6205, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "531 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6207, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "532 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6209, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "533 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6211, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "534 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6213, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "535 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6215, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "536 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6216, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "537 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6218, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "538 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6220, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "539 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6222, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "540 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6224, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "541 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6226, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "542 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6228, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "543 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6230, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "544 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6231, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "545 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6233, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "546 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6235, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "547 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6237, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "548 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6239, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "549 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6241, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "550 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6243, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "551 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6245, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "552 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6246, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "553 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6248, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "554 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6250, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "555 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6252, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "556 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6254, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "557 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6256, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "558 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6257, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "559 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6259, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "560 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6261, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "561 tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6263, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "562 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6265, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "563 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6266, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "564 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6268, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "565 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6270, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "566 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6272, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "567 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6274, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "568 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "569 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6277, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "570 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6279, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "571 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "572 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6283, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "573 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6284, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "574 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6286, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "575 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6288, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "576 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6290, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "577 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6292, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "578 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6293, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6295, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "580 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6297, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "581 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6299, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "582 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6300, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "583 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6302, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "584 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6304, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "585 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6306, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "586 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6307, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "587 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6309, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "588 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6311, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "589 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6313, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "590 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6314, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "591 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6316, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "592 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6318, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "593 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6320, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "594 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6321, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "595 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6323, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "596 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6325, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "597 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6327, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "598 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6328, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "599 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6330, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "600 tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6332, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "601 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6333, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "602 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6335, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "603 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6337, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "604 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6339, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "605 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6340, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "606 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6342, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "607 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6344, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "608 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6345, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "609 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6347, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "610 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6349, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "611 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6351, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "612 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6352, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "613 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6354, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "614 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6356, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "615 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6357, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "616 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6359, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "617 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6361, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "618 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6362, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "619 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6364, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "620 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "621 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6367, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "622 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6369, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "623 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6371, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "624 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6372, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "625 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6374, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "626 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6376, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "627 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6377, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "628 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6379, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "629 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6381, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "630 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6382, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "631 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6384, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "632 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6386, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "633 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6387, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "634 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6389, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "635 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6390, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "636 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6392, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "637 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6394, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "638 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6395, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "639 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6397, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "640 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6399, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "641 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6400, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "642 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6402, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "643 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6403, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "644 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6405, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "645 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6407, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "646 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6408, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "647 tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.6410, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "648 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6412, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "649 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6413, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "650 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6415, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "651 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6416, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "652 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6418, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "653 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6420, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "654 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6421, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "655 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6423, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "656 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6424, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "657 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6426, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "658 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6428, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "659 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6429, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "660 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6431, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "661 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6432, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "662 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6434, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "663 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6435, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "664 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6437, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "665 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6439, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "666 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6440, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "667 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6442, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "668 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6443, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "669 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6445, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "670 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6446, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "671 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6448, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "672 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6450, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "673 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6451, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "674 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6453, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "675 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6454, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "676 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6456, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "677 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6457, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "678 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6459, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "679 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6460, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "680 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6462, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "681 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6463, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "682 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6465, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "683 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6467, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "684 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6468, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "685 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6470, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "686 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6471, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "687 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6473, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "688 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6474, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "689 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6476, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "690 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6477, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "691 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6479, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "692 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6480, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "693 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6482, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "694 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6483, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "695 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6485, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "696 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6486, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "697 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6488, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "698 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6489, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "699 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6491, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "700 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6492, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "701 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6494, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "702 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6495, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "703 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6497, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "704 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6498, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "705 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6500, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "706 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6501, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "707 tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6503, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "708 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6504, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "709 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6506, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "710 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6507, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "711 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6509, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "712 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6510, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "713 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6512, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "714 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6513, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "715 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.6515, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "716 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6516, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "717 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6518, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "718 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6519, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "719 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6521, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "720 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6522, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "721 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6524, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "722 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6525, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "723 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6527, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "724 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6528, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "725 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6529, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "726 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6531, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "727 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6532, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "728 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6534, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "729 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6535, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "730 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6537, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "731 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6538, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "732 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6540, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "733 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6541, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "734 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6543, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "735 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6544, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "736 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6545, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "737 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6547, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "738 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6548, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "739 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6550, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "740 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6551, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "741 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "742 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6554, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "743 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "744 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6557, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "745 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6558, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "746 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6560, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "747 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6561, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "748 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6563, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "749 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6564, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "750 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6565, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "751 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6567, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "752 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6568, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "753 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6570, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "754 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6571, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "755 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6573, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "756 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6574, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "757 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6575, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "758 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6577, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "759 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6578, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "760 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6580, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "761 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6581, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "762 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6582, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "763 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6584, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "764 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6585, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "765 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6587, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "766 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6588, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "767 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6589, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "768 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6591, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "769 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6592, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "770 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6594, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "771 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6595, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "772 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6596, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "773 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6598, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "774 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6599, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "775 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6600, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "776 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6602, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "777 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6603, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "778 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6605, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "779 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6606, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "780 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6607, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "781 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6609, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "782 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6610, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6611, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "784 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6613, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "785 tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6614, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "786 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6616, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "787 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6617, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "788 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6618, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "789 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6620, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "790 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6621, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "791 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6622, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "792 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6624, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "793 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6625, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "794 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6626, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "795 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6628, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "796 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6629, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "797 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6630, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "798 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6632, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "799 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6633, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "800 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6634, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "801 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6636, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "802 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6637, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "803 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6638, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "804 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6640, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "805 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6641, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "806 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6642, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "807 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6644, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "808 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6645, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "809 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6646, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "810 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6648, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "811 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6649, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "812 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6650, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "813 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6652, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "814 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6653, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "815 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6654, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "816 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6656, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "817 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6657, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "818 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6658, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "819 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6660, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "820 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "821 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6662, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "822 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6664, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "823 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6665, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "824 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6666, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "825 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6668, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "826 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6669, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "827 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6670, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "828 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6672, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "829 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6673, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "830 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6674, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "831 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6675, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "832 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6677, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "833 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6678, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "834 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6679, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "835 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6681, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "836 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6682, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "837 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6683, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "838 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6684, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "839 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6686, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "840 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6687, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "841 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6688, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "842 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6690, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "843 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6691, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "844 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6692, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "845 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6693, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "846 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6695, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "847 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6696, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "848 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6697, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "849 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6699, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "850 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.6700, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "851 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6701, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "852 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "853 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6704, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "854 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "855 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6706, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "856 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6707, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "857 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6709, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "858 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6710, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "859 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6711, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "860 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6713, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "861 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6714, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "862 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6715, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "863 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6716, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "864 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6718, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "865 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6719, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "866 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6720, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "867 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6721, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "868 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6723, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "869 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6724, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "870 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6725, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "871 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "872 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6728, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "873 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "874 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6730, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "875 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6731, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "876 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6733, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "877 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6734, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "878 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6735, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "879 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6736, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "880 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6738, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "881 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6739, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "882 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6740, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "883 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6741, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "884 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6742, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "885 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6744, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "886 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6745, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "887 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6746, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "888 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6747, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "889 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6749, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "890 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6750, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "891 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6751, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "892 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6752, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "893 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6754, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "894 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6755, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "895 tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6756, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "896 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6757, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "897 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6758, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "898 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6760, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "899 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6761, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "900 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6762, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "901 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6763, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "902 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6764, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "903 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6766, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "904 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6767, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "905 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6768, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "906 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6769, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "907 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "908 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6772, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "909 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6773, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "910 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6774, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "911 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6775, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "912 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6777, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "913 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6778, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "914 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6779, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "915 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6780, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "916 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6781, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "917 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6783, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "918 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6784, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "919 tensor(0.0003, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6785, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "920 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6786, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "921 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6787, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "922 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6789, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "923 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6790, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "924 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6791, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "925 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6792, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "926 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6793, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "927 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6794, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "928 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6796, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "929 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6797, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "930 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6798, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "931 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6799, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "932 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6800, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "933 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6802, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "934 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6803, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "935 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6804, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "936 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6805, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "937 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6806, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "938 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6807, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "939 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6809, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "940 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6810, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "941 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6811, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "942 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6812, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "943 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6813, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "944 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6814, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "945 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6816, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "946 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6817, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "947 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6818, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "948 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6819, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "949 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6820, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "950 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6821, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "951 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6823, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "952 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6824, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "953 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6825, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "954 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6826, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "955 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6827, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "956 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6828, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "957 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6830, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "958 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6831, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "959 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6832, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "960 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6833, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "961 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "962 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6835, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "963 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6836, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "964 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6838, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "965 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6839, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "966 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6840, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "967 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6841, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "968 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6842, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "969 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6843, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "970 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6844, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "971 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6846, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "972 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6847, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "973 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6848, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "974 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6849, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "975 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6850, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "976 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6851, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "977 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6852, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "978 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6854, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "979 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6855, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "980 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6856, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "981 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6857, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "982 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6858, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "983 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "984 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6860, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "985 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6861, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "986 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6863, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "987 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(0.6864, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "988 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6865, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "989 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6866, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "990 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6867, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "991 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6868, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "992 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6869, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "993 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6870, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "994 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6872, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "995 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6873, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "996 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6874, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "997 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6875, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "998 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "999 tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(1.)\n",
      "The Current Loss: tensor(0.6877, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "Accuracy on test set: 0.8785714507102966\n"
     ]
    }
   ],
   "source": [
    "n_input = G.ndata['feat'].shape[1]\n",
    "n_hidden = 16\n",
    "n_out = dataset.num_classes\n",
    "\n",
    "model = SAGEConv(n_input, n_hidden, n_out)\n",
    "\n",
    "trigger_times=0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 1000\n",
    "patience=5\n",
    "last_loss=0\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(G, features)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(logits[train_mask], G.ndata['label'][train_mask])\n",
    "    print(epoch, loss)\n",
    "    print('acc', (logits[train_mask].argmax(dim=1) == G.ndata['label'][train_mask]).float().mean())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    current_loss = validation(model,  nn.CrossEntropyLoss())\n",
    "    print('The Current Loss:', current_loss)\n",
    "\n",
    "    if (current_loss - last_loss) > 0.1:\n",
    "            trigger_times += 1\n",
    "            last_loss=current_loss\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "\n",
    "    else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "            last_loss=current_loss\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(G, features)\n",
    "    loss_test = nn.CrossEntropyLoss()(pred[test_mask], G.ndata['label'][test_mask])\n",
    "accuracy = (pred[test_mask].argmax(dim=1) == G.ndata['label'][test_mask]).float().mean()\n",
    "print(f\"Accuracy on test set: {accuracy.item()}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f80f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loss_function):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output = model(G, features)\n",
    "    loss = loss_function(logits[val_mask].view(500, -1), G.ndata['label'][val_mask])\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e48a2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(4.1434, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.0240)\n",
      "The Current Loss: tensor(4.1442, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "1 tensor(4.1012, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1920)\n",
      "The Current Loss: tensor(4.1016, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "2 tensor(4.0573, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1900)\n",
      "The Current Loss: tensor(4.0576, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "3 tensor(4.0088, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1660)\n",
      "The Current Loss: tensor(4.0093, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "4 tensor(3.9559, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1600)\n",
      "The Current Loss: tensor(3.9565, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "5 tensor(3.8989, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1560)\n",
      "The Current Loss: tensor(3.8996, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "6 tensor(3.8378, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1540)\n",
      "The Current Loss: tensor(3.8386, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "7 tensor(3.7723, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1520)\n",
      "The Current Loss: tensor(3.7732, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "8 tensor(3.7021, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1530)\n",
      "The Current Loss: tensor(3.7032, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "9 tensor(3.6276, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1530)\n",
      "The Current Loss: tensor(3.6289, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "10 tensor(3.5491, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1520)\n",
      "The Current Loss: tensor(3.5507, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "11 tensor(3.4668, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1530)\n",
      "The Current Loss: tensor(3.4686, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "12 tensor(3.3808, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1540)\n",
      "The Current Loss: tensor(3.3828, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "13 tensor(3.2916, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1560)\n",
      "The Current Loss: tensor(3.2938, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "14 tensor(3.1997, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1570)\n",
      "The Current Loss: tensor(3.2020, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "15 tensor(3.1052, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1580)\n",
      "The Current Loss: tensor(3.1075, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "16 tensor(3.0088, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1590)\n",
      "The Current Loss: tensor(3.0110, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "17 tensor(2.9115, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1590)\n",
      "The Current Loss: tensor(2.9133, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "18 tensor(2.8140, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1600)\n",
      "The Current Loss: tensor(2.8155, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "19 tensor(2.7174, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1620)\n",
      "The Current Loss: tensor(2.7185, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "20 tensor(2.6227, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1670)\n",
      "The Current Loss: tensor(2.6233, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "21 tensor(2.5309, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1730)\n",
      "The Current Loss: tensor(2.5310, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "22 tensor(2.4430, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.1850)\n",
      "The Current Loss: tensor(2.4426, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "23 tensor(2.3600, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.2010)\n",
      "The Current Loss: tensor(2.3590, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "24 tensor(2.2825, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.2470)\n",
      "The Current Loss: tensor(2.2811, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "25 tensor(2.2110, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3120)\n",
      "The Current Loss: tensor(2.2092, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "26 tensor(2.1456, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3810)\n",
      "The Current Loss: tensor(2.1435, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "27 tensor(2.0862, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4220)\n",
      "The Current Loss: tensor(2.0840, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "28 tensor(2.0323, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4460)\n",
      "The Current Loss: tensor(2.0303, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "29 tensor(1.9837, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4450)\n",
      "The Current Loss: tensor(1.9819, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "30 tensor(1.9397, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4300)\n",
      "The Current Loss: tensor(1.9385, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "31 tensor(1.9000, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4010)\n",
      "The Current Loss: tensor(1.8998, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "32 tensor(1.8645, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3710)\n",
      "The Current Loss: tensor(1.8654, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "33 tensor(1.8329, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3490)\n",
      "The Current Loss: tensor(1.8352, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "34 tensor(1.8049, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3320)\n",
      "The Current Loss: tensor(1.8090, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "35 tensor(1.7805, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3250)\n",
      "The Current Loss: tensor(1.7865, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "36 tensor(1.7591, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3230)\n",
      "The Current Loss: tensor(1.7672, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "37 tensor(1.7403, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3230)\n",
      "The Current Loss: tensor(1.7508, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "38 tensor(1.7237, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3230)\n",
      "The Current Loss: tensor(1.7365, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "39 tensor(1.7084, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3230)\n",
      "The Current Loss: tensor(1.7238, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "40 tensor(1.6940, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3230)\n",
      "The Current Loss: tensor(1.7118, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "41 tensor(1.6798, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3260)\n",
      "The Current Loss: tensor(1.7001, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "42 tensor(1.6653, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3280)\n",
      "The Current Loss: tensor(1.6880, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "43 tensor(1.6501, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3290)\n",
      "The Current Loss: tensor(1.6752, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "44 tensor(1.6341, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3320)\n",
      "The Current Loss: tensor(1.6616, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "45 tensor(1.6174, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3450)\n",
      "The Current Loss: tensor(1.6469, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "46 tensor(1.6000, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3620)\n",
      "The Current Loss: tensor(1.6314, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "47 tensor(1.5821, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3830)\n",
      "The Current Loss: tensor(1.6156, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "48 tensor(1.5641, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.3970)\n",
      "The Current Loss: tensor(1.5997, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "49 tensor(1.5455, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4150)\n",
      "The Current Loss: tensor(1.5831, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "50 tensor(1.5260, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4380)\n",
      "The Current Loss: tensor(1.5655, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "51 tensor(1.5060, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4540)\n",
      "The Current Loss: tensor(1.5476, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "52 tensor(1.4861, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4750)\n",
      "The Current Loss: tensor(1.5297, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "53 tensor(1.4663, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.4990)\n",
      "The Current Loss: tensor(1.5118, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "54 tensor(1.4458, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5090)\n",
      "The Current Loss: tensor(1.4932, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "55 tensor(1.4246, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5240)\n",
      "The Current Loss: tensor(1.4740, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "56 tensor(1.4024, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5360)\n",
      "The Current Loss: tensor(1.4538, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "57 tensor(1.3792, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5440)\n",
      "The Current Loss: tensor(1.4327, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "58 tensor(1.3550, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5580)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Current Loss: tensor(1.4106, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "59 tensor(1.3299, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5680)\n",
      "The Current Loss: tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "60 tensor(1.3039, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5820)\n",
      "The Current Loss: tensor(1.3638, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "61 tensor(1.2771, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.5920)\n",
      "The Current Loss: tensor(1.3392, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "62 tensor(1.2499, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6040)\n",
      "The Current Loss: tensor(1.3143, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "63 tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6090)\n",
      "The Current Loss: tensor(1.2892, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "64 tensor(1.1951, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6120)\n",
      "The Current Loss: tensor(1.2641, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "65 tensor(1.1680, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6190)\n",
      "The Current Loss: tensor(1.2396, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "66 tensor(1.1409, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6240)\n",
      "The Current Loss: tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "67 tensor(1.1140, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6340)\n",
      "The Current Loss: tensor(1.1911, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "68 tensor(1.0874, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6550)\n",
      "The Current Loss: tensor(1.1674, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "69 tensor(1.0614, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6690)\n",
      "The Current Loss: tensor(1.1446, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "70 tensor(1.0360, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.6900)\n",
      "The Current Loss: tensor(1.1226, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "71 tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7050)\n",
      "The Current Loss: tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "72 tensor(0.9866, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7150)\n",
      "The Current Loss: tensor(1.0799, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "73 tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7250)\n",
      "The Current Loss: tensor(1.0594, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "74 tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7310)\n",
      "The Current Loss: tensor(1.0395, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "75 tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7450)\n",
      "The Current Loss: tensor(1.0202, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "76 tensor(0.8943, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7520)\n",
      "The Current Loss: tensor(1.0016, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "77 tensor(0.8727, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7660)\n",
      "The Current Loss: tensor(0.9837, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "78 tensor(0.8516, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7720)\n",
      "The Current Loss: tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "79 tensor(0.8311, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7810)\n",
      "The Current Loss: tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "80 tensor(0.8110, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7830)\n",
      "The Current Loss: tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "81 tensor(0.7913, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7880)\n",
      "The Current Loss: tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "82 tensor(0.7721, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.7960)\n",
      "The Current Loss: tensor(0.9054, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "83 tensor(0.7533, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8010)\n",
      "The Current Loss: tensor(0.8920, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "84 tensor(0.7349, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8110)\n",
      "The Current Loss: tensor(0.8792, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "85 tensor(0.7169, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8180)\n",
      "The Current Loss: tensor(0.8668, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "86 tensor(0.6992, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8210)\n",
      "The Current Loss: tensor(0.8549, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "87 tensor(0.6819, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8260)\n",
      "The Current Loss: tensor(0.8434, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "88 tensor(0.6649, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8350)\n",
      "The Current Loss: tensor(0.8324, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "89 tensor(0.6482, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8390)\n",
      "The Current Loss: tensor(0.8219, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "90 tensor(0.6318, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8450)\n",
      "The Current Loss: tensor(0.8119, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "91 tensor(0.6157, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8520)\n",
      "The Current Loss: tensor(0.8023, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "92 tensor(0.6000, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8580)\n",
      "The Current Loss: tensor(0.7930, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "93 tensor(0.5846, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8670)\n",
      "The Current Loss: tensor(0.7841, grad_fn=<NllLossBackward0>)\n",
      "trigger times: 0\n",
      "94 tensor(0.5696, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8690)\n",
      "The Current Loss: tensor(0.7756, grad_fn=<NllLossBackward0>)\n",
      "95 tensor(0.5550, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8720)\n",
      "The Current Loss: tensor(0.7674, grad_fn=<NllLossBackward0>)\n",
      "96 tensor(0.5407, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8720)\n",
      "The Current Loss: tensor(0.7595, grad_fn=<NllLossBackward0>)\n",
      "97 tensor(0.5267, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8780)\n",
      "The Current Loss: tensor(0.7520, grad_fn=<NllLossBackward0>)\n",
      "98 tensor(0.5131, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8810)\n",
      "The Current Loss: tensor(0.7448, grad_fn=<NllLossBackward0>)\n",
      "99 tensor(0.4997, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8870)\n",
      "The Current Loss: tensor(0.7379, grad_fn=<NllLossBackward0>)\n",
      "100 tensor(0.4866, grad_fn=<NllLossBackward0>)\n",
      "acc tensor(0.8900)\n",
      "The Current Loss: tensor(0.7314, grad_fn=<NllLossBackward0>)\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Accuracy on test set: 0.75\n"
     ]
    }
   ],
   "source": [
    "n_input = G.ndata['feat'].shape[1]\n",
    "n_hidden = 16\n",
    "n_out = dataset.num_classes\n",
    "trigger_times=0\n",
    "model = GATConv(n_input, n_hidden, n_out)\n",
    "\n",
    "last_loss=0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 1000\n",
    "patience=7\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(G, features)\n",
    "#     print(logits[train_mask].shape)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(logits[train_mask].view(1000, -1), G.ndata['label'][train_mask])\n",
    "    last_loss=loss\n",
    "    print(epoch, loss)\n",
    "    print('acc', (logits[train_mask].view(1000, -1).argmax(dim=1) == G.ndata['label'][train_mask]).float().mean())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    current_loss = validation(model,  nn.CrossEntropyLoss())\n",
    "    print('The Current Loss:', current_loss)\n",
    "\n",
    "    if (current_loss - last_loss) > 0.2:\n",
    "            trigger_times += 1\n",
    "            last_loss=current_loss\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "\n",
    "    else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "            last_loss=current_loss\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(G, features)\n",
    "accuracy = (pred[test_mask].view(140, -1).argmax(dim=1) == G.ndata['label'][test_mask]).float().mean()\n",
    "print(f\"Accuracy on test set: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de9aafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'Moдель': ['GraphConv', 'SAGEConv', 'GatConv'], 'Loss на обучении': [0.8, 0.003, 0.4], 'Acc на обучении': [0.96, 0.67, 0.89], 'Acc на тесте': [0.70, 0.56, 0.76], 'Кол-во эпох до ранней остановки': [54, 1000, 101]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99cd400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moдель</th>\n",
       "      <th>Loss на обучении</th>\n",
       "      <th>Acc на обучении</th>\n",
       "      <th>Acc на тесте</th>\n",
       "      <th>Кол-во эпох до ранней остановки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GraphConv</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.70</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAGEConv</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GatConv</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Moдель  Loss на обучении  Acc на обучении  Acc на тесте  \\\n",
       "0  GraphConv             0.800             0.96          0.70   \n",
       "1   SAGEConv             0.003             0.67          0.56   \n",
       "2    GatConv             0.400             0.89          0.76   \n",
       "\n",
       "   Кол-во эпох до ранней остановки  \n",
       "0                               54  \n",
       "1                             1000  \n",
       "2                              101  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9175f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b541778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055ae63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08e817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a876507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
